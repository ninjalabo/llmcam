{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f0ff07-13fe-4ebe-970d-4848f7462e09",
   "metadata": {},
   "source": [
    "# chat UI in fastHTML\n",
    "\n",
    "> chat UI implemented in fastHTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36b977-f531-4d05-af7a-1761ef5d2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp chat_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd185b2-ec84-46d1-8474-9038ee3eb232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17c22c",
   "metadata": {},
   "source": [
    "## Chat App initialization\n",
    "\n",
    "Start by creating the chat application with `FastHTML`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import uvicorn\n",
    "import uuid\n",
    "import os\n",
    "import asyncio\n",
    "from fasthtml.common import *\n",
    "from fastcore.parallel import startthread\n",
    "from typing import Callable, Optional\n",
    "\n",
    "from llmcam.fn_to_fc import capture_youtube_live_frame_and_save, ask_gpt4v_about_image_file\n",
    "from llmcam.fn_to_fc import tool_schema, complete, form_msg\n",
    "from llmcam.store import add_api_tools, add_function_tools, remove_tools\n",
    "from llmcam.store import execute_handler_core, handler_schema\n",
    "from llmcam.yolo import detect_objects\n",
    "from llmcam.dtcam import cap\n",
    "from llmcam.file_manager import list_image_files, list_detection_files\n",
    "from llmcam.plotting import plot_object\n",
    "from llmcam.notification import notification_stream_core, process_notification_schema, StreamThread\n",
    "from llmcam.bash_command import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd9eb2",
   "metadata": {},
   "source": [
    "### Pseudo-database and session FC setup\n",
    "\n",
    "Our current tool stack include several functions that capitalize on having one or more universal pointers (store manager functions depend on a global `tools`, notifications depend on a global `stream_thread` and sender function). However, such universal pointers will not work in web settings, where multiple users can simultaneously access the website. Therefore, the idea is to introduce sessions and universal pointers that are mappings of these sessions to actual values the tools can use. We also introduce `session_id` as a new metadata field for our tools and implement custom fixup functions that extract the correct values from the mappings and pass down to our already implemented tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900cbb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Set up database for information per session\n",
    "session_messages = {}  # Messages for each session\n",
    "session_tools = {}  # Tools for each session\n",
    "session_notis = {}  # Sender and notification streams for each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Set up default tools\n",
    "default_tools = [tool_schema(fn) for fn in (\n",
    "    capture_youtube_live_frame_and_save, \n",
    "    ask_gpt4v_about_image_file,\n",
    "    detect_objects,\n",
    "    cap,\n",
    "    list_image_files,\n",
    "    list_detection_files,\n",
    "    plot_object,\n",
    "    execute_bash_command,\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b97d14",
   "metadata": {},
   "source": [
    "Here, we implement the schema preparation to attach `session_id` as metadata and `fixup` function for store manager functions and actual `fixup` function that extracts correct `tools` pointer to pass to `execute_handler_core`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4cd069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Utility functions to manage tools per session\n",
    "def prepare_handler_schemas(\n",
    "    session_id: str,  # Session ID to use\n",
    "    fixup: Callable = None,  # Optional function to fix up the execution\n",
    "):\n",
    "    return [\n",
    "        handler_schema(function, service_name=\"toolbox_manager\", fixup=fixup, session_id=session_id) for \\\n",
    "        function in [add_api_tools, add_function_tools, remove_tools]\n",
    "    ]\n",
    "\n",
    "def execute_handler(\n",
    "    function_name: str,  # Name of the function to execute\n",
    "    session_id: str,  # Session ID to use\n",
    "    **kwargs,  # Additional arguments to pass to the function\n",
    "):\n",
    "    tools = session_tools[session_id]\n",
    "    return execute_handler_core(tools, function_name, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b5000",
   "metadata": {},
   "source": [
    "The notifications system is quite more complicated. It relies on also subtools to pass in sub GPT in the separate thread running notification stream. These subtools include a tool to send notification and a tool to stop the stream. The default utilities function for this uses a common global pointer `stream_thread`, which will not work in this case. Hence, we need to implement the new utilities function:\n",
    "\n",
    "- `execute_send_notification`: Instead of implementing the actual function, a `fixup` is implemented to capitalize on the metadata field `session_id`. This function also utilizes the feature that a websocket sender function can be saved in global collections -  [example with real time Chat App](https://docs.fastht.ml/explains/websockets.html#real-time-chat-app). Therefore, it simply retrieves the sender function with `session_id` and uses it to send the message.  \n",
    "- `execute_stopper`: Instead of implementing the actual function, a `fixup` is implemented to capitalize on the metadata field `session_id` and `noti_id`. The idea is that each notification stream is given a unique ID and saved in a mapping of IDs to notification streams. This mapping is also retrievable by `session_id`.\n",
    "\n",
    "We also need to implement a custom `start_notification_stream` function which will be used as a tool by GPT Function Calling. This function will utilize `session_id` and create a unique `noti_id` to define schemas for subtools with these values as metadata. It also defines these schemas such that the `module` metadata is missing to ensure the attached `fixup` function will be called instead. However, because it uses a metadata field `session_id`, it will also need to have a `fixup` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62eab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Utility functions to manage notifications per session\n",
    "def execute_send_notification(function_name, session_id, msg, **kwargs):\n",
    "    \"\"\"Fixup function to send a notification.\"\"\"\n",
    "    global session_notis\n",
    "    sender, _ = session_notis[session_id]  # Get the sender\n",
    "    sender(msg)\n",
    "    return 'Notification sent'\n",
    "\n",
    "def execute_stopper(function_name, session_id, noti_id, **kwargs):\n",
    "    \"\"\"Fixup function to stop a notification stream.\"\"\"\n",
    "    global session_notis\n",
    "    _, notis = session_notis[session_id]  # Get the notification streams \n",
    "    notis[noti_id].stop()  # Stop the stream with the given ID\n",
    "    return 'Notification stream stopped'\n",
    "\n",
    "def start_notification_stream(\n",
    "    session_id: str,  # Session ID to use\n",
    "    messages: list,  # All the previous messages in the conversation\n",
    "):\n",
    "    \"\"\"Start a notification stream to monitor a process described in messages.\"\"\"\n",
    "    global session_notis\n",
    "    global session_tools\n",
    "\n",
    "    _, notis = session_notis[session_id]  # Get the notification streams\n",
    "\n",
    "    # Define a new notification stream with a unique ID\n",
    "    noti_id = str(uuid.uuid4())\n",
    "    \n",
    "    # Describe the sender and stopper functions\n",
    "    sender_schema = {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'send_notification',\n",
    "            'description': 'Send a notification with a message',\n",
    "            'metadata': {\n",
    "                'session_id': session_id\n",
    "            },\n",
    "            'parameters': {'type': 'object',\n",
    "                'properties': {'msg': {'type': 'string',\n",
    "                'description': 'No description provided.'}},\n",
    "                'required': ['msg']},\n",
    "            'fixup': f\"{execute_send_notification.__module__}.{execute_send_notification.__name__}\"\n",
    "        },\n",
    "    }\n",
    "\n",
    "    stopper_schema = {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'stop_notification',\n",
    "            'description': 'Stop the notification stream',\n",
    "            'parameters': {'type': 'object', 'properties': {}, 'required': []},\n",
    "            'metadata': {\n",
    "                'session_id': session_id,\n",
    "                'noti_id': noti_id\n",
    "            },\n",
    "            'fixup': f\"{execute_stopper.__module__}.{execute_stopper.__name__}\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Define a function to start the stream\n",
    "    def stream_starter(tools, messages):\n",
    "        notis[noti_id] = StreamThread(noti_id, tools, messages)\n",
    "        notis[noti_id].start()\n",
    "\n",
    "    # Extract the tools for the session\n",
    "    tools = session_tools[session_id]\n",
    "\n",
    "    # Start the notification stream\n",
    "    notification_stream_core(\n",
    "        tools, \n",
    "        messages,\n",
    "        stream_starter=stream_starter,\n",
    "        send_notification_schema=sender_schema,\n",
    "        stream_stopper_schema=stopper_schema\n",
    "    )\n",
    "\n",
    "    # Return the ID of the notification stream  \n",
    "    return f\"Notification stream started with ID {noti_id}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8b135",
   "metadata": {},
   "source": [
    "Define the `fixup` function for starting a notification stream which passes in `session_id` to `start_notification_stream`. Define also a function to attach `session_id` as metadata for the notification FC schema and attach the `fixup` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b71e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_notification_schemas(\n",
    "        session_id: str,  # Session ID to use\n",
    "        fixup: Callable = None,  # Optional function to fix up the execution\n",
    "    ):  # Prepare the notification schema\n",
    "    schema = process_notification_schema(start_notification_stream)  # Get the schema for starting notification stream\n",
    "    # Set additional metadata\n",
    "    schema['function']['metadata']['session_id'] = session_id  \n",
    "    if fixup: schema['function']['fixup'] = f\"{fixup.__module__}.{fixup.__name__}\"\n",
    "    return schema\n",
    "\n",
    "def execute_start_notification_stream(function_name, session_id, messages, **kwargs):\n",
    "    \"\"\"Fixup function to start a notification stream.\"\"\"\n",
    "    return start_notification_stream(session_id, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b0e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def init_session(session_id: Optional[str] = None):\n",
    "    if session_id is None or session_id not in session_messages:\n",
    "        # Initialize tools in session tools and create a session ID\n",
    "        session_id = str(uuid.uuid4())\n",
    "\n",
    "        # Add default tools, prepare handler schemas, and prepare notification schema\n",
    "        session_tools[session_id] = []\n",
    "        session_tools[session_id].extend(default_tools)\n",
    "        session_tools[session_id].extend(prepare_handler_schemas(session_id, execute_handler))\n",
    "        session_tools[session_id].append(prepare_notification_schemas(session_id, execute_start_notification_stream))\n",
    "\n",
    "        # Initialize messages in session messages\n",
    "        session_messages[session_id] = []\n",
    "    \n",
    "    return session_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f07a47",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b1df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Set up the app, including daisyui and tailwind for the chat component\n",
    "hdrs = (picolink,\n",
    "        Link(rel=\"icon\", href=f\"\"\"{os.getenv(\"LLMCAM_DATA\", \"../data\").split(\"/\")[-1]}/favicon.ico\"\"\", type=\"image/png\"),\n",
    "        Script(src=\"https://cdn.tailwindcss.com\"),\n",
    "        Link(rel=\"stylesheet\", href=\"https://cdn.jsdelivr.net/npm/daisyui@4.11.1/dist/full.min.css\"),\n",
    "        Script(src=\"https://unpkg.com/htmx.org\"),\n",
    "        Style(\"p {color: black;}\"),\n",
    "        Style(\"li {color: black;}\"),\n",
    "        MarkdownJS(), HighlightJS(langs=['python', 'javascript', 'html', 'css']))\n",
    "app = FastHTML(hdrs=hdrs, exts=\"ws\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0211a31",
   "metadata": {},
   "source": [
    "## Chat components\n",
    "\n",
    "Basic chat UI components can include Chat Message and a Chat Input. For a Chat Message, the important attributes are the actual message (str) and the role of the message owner (user - boolean value whether the owner is the user, not the AI assistant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6c7f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Chat message component (renders a chat bubble)\n",
    "def ChatMessage(\n",
    "        msg: str,  # Message to display\n",
    "        user: bool  # Whether the message is from the user or assistant\n",
    "    ):  # Returns a Div containing the chat bubble\n",
    "    # Set class to change displayed style of bubble\n",
    "    content_class = \"chat-bubble chat-bubble-primary\" if user else \"\"\n",
    "    content_class += \" marked py-2\"\n",
    "    return  Div(cls=f\"chat chat-end py-4\" if user else \"py-4\")(\n",
    "                Div('User' if user else 'Assistant', cls=\"chat-header\"),\n",
    "                Div(\n",
    "                    msg,\n",
    "                    cls=content_class,\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d96926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L183){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChatMessage\n",
       "\n",
       ">      ChatMessage (msg:str, user:bool)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| msg | str | Message to display |\n",
       "| user | bool | Whether the message is from the user or assistant |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L183){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChatMessage\n",
       "\n",
       ">      ChatMessage (msg:str, user:bool)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| msg | str | Message to display |\n",
       "| user | bool | Whether the message is from the user or assistant |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChatMessage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc84d14",
   "metadata": {},
   "source": [
    "For the chat input, set the name for submitting a new message via form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6bbd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# The input field for the user message. Also used to clear the\n",
    "# input field after sending a message via an OOB swap\n",
    "def ChatInput():  # Returns an input field for the user message\n",
    "    return Input(name='msg', id='msg-input', placeholder=\"Type a message\",\n",
    "                 cls=\"input input-bordered w-full rounded-l-2xl\", \n",
    "                 hx_swap_oob='true'  # Re-render the element to remove submitted message\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a8814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L201){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChatInput\n",
       "\n",
       ">      ChatInput ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L201){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChatInput\n",
       "\n",
       ">      ChatInput ()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChatInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986a51e",
   "metadata": {},
   "source": [
    "### Action Buttons\n",
    "\n",
    "Simple actions for creating a new message from the user side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cba3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ActionButton(\n",
    "        session_id: str,  # Session ID to use\n",
    "        content: str,  # Text to display on the button\n",
    "        message: str = None  # Message to send when the button is clicked\n",
    "    ):  # Returns a button with the given content\n",
    "\n",
    "    return Form(\n",
    "        ws_send=True,\n",
    "        hx_ext='ws', ws_connect='/wschat',\n",
    "    )(\n",
    "        Hidden(session_id, name=\"session_id\"),\n",
    "        Hidden(content if message is None else message, name=\"msg\"),\n",
    "        Button(\n",
    "            content, \n",
    "            cls=\"btn btn-secondary rounded-2 h-fit\", \n",
    "        )\n",
    "    )\n",
    "\n",
    "def ActionPanel(\n",
    "        session_id: str  # Session ID to use\n",
    "    ):  # Returns a panel of action buttons\n",
    "    return Div(\n",
    "        P(\"Quick actions\", cls=\"text-lg text-black\"),\n",
    "        ActionButton(session_id, \"Introduce your model GPT-4o\"),\n",
    "        ActionButton(session_id,\n",
    "            \"Extract information from a YouTube Live\", \n",
    "            \"Capture and extract information from a YouTube Live. Use the default link.\"),\n",
    "        cls=\"flex flex-col h-fit gap-4 py-4 px-4\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59ea66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L208){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ActionButton\n",
       "\n",
       ">      ActionButton (session_id:str, content:str, message:str=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| session_id | str |  | Session ID to use |\n",
       "| content | str |  | Text to display on the button |\n",
       "| message | str | None | Message to send when the button is clicked |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L208){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ActionButton\n",
       "\n",
       ">      ActionButton (session_id:str, content:str, message:str=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| session_id | str |  | Session ID to use |\n",
       "| content | str |  | Text to display on the button |\n",
       "| message | str | None | Message to send when the button is clicked |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ActionButton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f47bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L226){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ActionPanel\n",
       "\n",
       ">      ActionPanel (session_id:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| session_id | str | Session ID to use |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L226){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ActionPanel\n",
       "\n",
       ">      ActionPanel (session_id:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| session_id | str | Session ID to use |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ActionPanel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cce0ff",
   "metadata": {},
   "source": [
    "### Tools panel\n",
    "\n",
    "Sidebar-panel for displaying current list of available (loaded) tools in a user-session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ToolPanel(\n",
    "        session_id: str  # Session ID to use\n",
    "    ):  # Returns a panel of usable tools\n",
    "\n",
    "    available_services = session_tools.get(session_id, [])\n",
    "\n",
    "    # Generate list items for each available tool\n",
    "    items = []\n",
    "    if available_services:\n",
    "        for service in available_services:\n",
    "            service_desc = service['function']['description']\n",
    "            items.append(Li(f\"{service_desc}\", cls=\"text-sm text-black\"))\n",
    "    else:\n",
    "        items.append(Li(\"No services available\", cls=\"text-sm italic text-gray-500\"))\n",
    "\n",
    "    return Div(\n",
    "        P(\"Available Tools\", cls=\"text-lg text-black\"),\n",
    "        Ul(*items, cls=\"list-disc list-inside px-6\", style=\"max-height: 800px; overflow-y:auto;\"),\n",
    "        id=\"toollist\",\n",
    "        cls=\"flex flex-col h-fit gap-4 py-4 px-4\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445d2453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L239){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ToolPanel\n",
       "\n",
       ">      ToolPanel (session_id:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| session_id | str | Session ID to use |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L239){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ToolPanel\n",
       "\n",
       ">      ToolPanel (session_id:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| session_id | str | Session ID to use |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ToolPanel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529b908",
   "metadata": {},
   "source": [
    "### Notifications\n",
    "\n",
    "The idea of sending notifications from a background task / websocket with FastHTML is to send an HTMX update, then detect and extract information from the event via a document event listener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1acd2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def NotiMessage(\n",
    "        message: str = \"No message\"  # Message to display\n",
    "    ):  # Returns a notification message hidden from the UI view\n",
    "    return Hidden(message, id=\"notification\", cls=\"text-black\")\n",
    "\n",
    "def NotiButton(\n",
    "        session_id: str  # Session ID to use\n",
    "    ):  # Returns a hidden button to trigger notification websocket connection\n",
    "    return Form(\n",
    "        ws_send=True,\n",
    "        hx_ext='ws', ws_connect='/wsnoti',\n",
    "        style=\"display: none;\"\n",
    "    )(\n",
    "        Hidden(session_id, name=\"session_id\"),\n",
    "        Button(\n",
    "            \"Notification\", \n",
    "            id=\"connect-btn\", \n",
    "            cls=\"btn btn-primary rounded-2 h-fit\", \n",
    "            style=\"display: none;\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca2615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Event listener to handle notifications when the element #notification is loaded\n",
    "noti_script = Script(\"\"\"\n",
    "    // Automatically click the hidden button to connect to the notification websocket\n",
    "    window.addEventListener('load', function() {\n",
    "        let connectButton = document.querySelector('#connect-btn');\n",
    "        if (connectButton) {\n",
    "            connectButton.click();\n",
    "            console.log(\"Hidden button clicked on page load!\");\n",
    "        }\n",
    "    });\n",
    "                     \n",
    "    // Listen for the htmx:load event on the document body\n",
    "    document.body.addEventListener('htmx:load', function(event) {\n",
    "        if (event.target.id === \"notification\") {\n",
    "            let htDivElement = event.detail.elt; // Extract the HtDiv element\n",
    "\n",
    "            // Find the input element inside the HtDiv and extract its value\n",
    "            let inputElement = htDivElement.querySelector('input');\n",
    "            if (inputElement) {\n",
    "                let inputValue = inputElement.value;\n",
    "                alert(inputValue);\n",
    "            } else {\n",
    "                console.log(\"Input element not found.\");\n",
    "            }\n",
    "        }\n",
    "    });\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174209ca",
   "metadata": {},
   "source": [
    "## Router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b9a76",
   "metadata": {},
   "source": [
    "### Home page\n",
    "The home page should contain our message list and the Chat Input. The main page can be extracted by accessing the index (root) endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "scroll_script = Script(\"\"\"\n",
    "  // Function to scroll to the bottom of an element\n",
    "  function scrollToBottom(element) {\n",
    "    element.scrollTop = element.scrollHeight;\n",
    "  }\n",
    "\n",
    "  // Reference the expanding element\n",
    "  const expandingElement = document.getElementById('chatlist');\n",
    "\n",
    "  // Observe changes to the element's content and scroll down automatically\n",
    "  const observer = new MutationObserver(() => {\n",
    "    scrollToBottom(expandingElement);\n",
    "  });\n",
    "\n",
    "  // Start observing the expanding element for changes\n",
    "  observer.observe(expandingElement, { childList: true, subtree: true });\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61c0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "title_script = Script(\"\"\"\n",
    "    // Function to set the title of the page\n",
    "    document.title = \"LLMCAM\";\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@app.get('/')\n",
    "async def index(session):\n",
    "    # Initialize the session\n",
    "    session_id = init_session(session_id=session.get('session_id'))\n",
    "    \n",
    "    # Set up the chat UI\n",
    "    sidebar = Div(\n",
    "        ActionPanel(session_id=session_id),\n",
    "        ToolPanel(session_id=session_id),\n",
    "        NotiButton(session_id=session_id),\n",
    "        NotiMessage(),\n",
    "        cls=\"w-[50vw] flex flex-col p-0\",\n",
    "        style=\"background-color: WhiteSmoke;\"\n",
    "    )\n",
    "    page =  Div(cls=\"w-full flex flex-col p-0\")(  # Main page\n",
    "        Form(\n",
    "            ws_send=True,\n",
    "            hx_ext='ws', ws_connect='/wschat',\n",
    "            cls=\"w-full flex flex-col px-24 h-[100vh]\"\n",
    "        )(\n",
    "            Hidden(session_id, name=\"session_id\"),\n",
    "            # The chat list\n",
    "            Div(id=\"chatlist\", cls=\"chat-box overflow-y-auto flex-1 w-full mt-10 p-4\")(\n",
    "                # One initial message from AI assistant\n",
    "                ChatMessage(\"Hello! I'm a chatbot. How can I help you today?\", False),\n",
    "            ),\n",
    "            # Input form\n",
    "            Div(cls=\"h-fit mb-5 mt-5 flex space-x-2 mt-2 p-4\")(\n",
    "                Group(\n",
    "                    ChatInput(), \n",
    "                    Button(\"Send\", cls=\"btn btn-primary rounded-r-2xl\"))\n",
    "            ),\n",
    "            scroll_script\n",
    "        ),\n",
    "    )\n",
    "    return Main(\n",
    "        noti_script,\n",
    "        title_script,\n",
    "        sidebar,\n",
    "        page, \n",
    "        title=\"Chatbot\",\n",
    "        data_theme=\"wireframe\",\n",
    "        cls=\"h-[100vh] w-full relative flex flex-row items-stretch overflow-hidden transition-colors z-0 p-0\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd32ac",
   "metadata": {},
   "source": [
    "### Notification websockets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecfdd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def noti_disconnect(ws):\n",
    "    \"\"\"Remove session ID from session notification sender on websocket disconnect\"\"\"\n",
    "    session_id = ws.scope.get(\"session_id\")\n",
    "    if session_id in session_messages:\n",
    "        del session_messages[session_id]\n",
    "    if session_id in session_tools:\n",
    "        del session_tools[session_id]\n",
    "    if session_id in session_notis:\n",
    "        del session_notis[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@app.ws('/wsnoti')\n",
    "async def wsnoti(ws, send, session_id: str):\n",
    "    # Initialize the session\n",
    "    session_id = init_session(session_id=session_id)\n",
    "\n",
    "    # Set the session ID in the websocket scope\n",
    "    ws.scope[\"session_id\"] = session_id\n",
    "\n",
    "    # Set up the notification sender for the session\n",
    "    def send_noti(message):\n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "        except RuntimeError:  # No current event loop in this thread\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "    \n",
    "        if loop.is_running():\n",
    "            # Schedule the task on the running loop\n",
    "            asyncio.create_task(send(Div(NotiMessage(message), id=\"notification\", hx_swap_oob=\"true\")))\n",
    "        else:\n",
    "            # Create and run a new loop\n",
    "            loop.run_until_complete(send(Div(NotiMessage(message), id=\"notification\", hx_swap_oob=\"true\")))\n",
    "    \n",
    "    session_notis[session_id] = (send_noti, {})\n",
    "\n",
    "    # Send a notification to the client\n",
    "    send_noti(\"Notification service enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a035fe",
   "metadata": {},
   "source": [
    "Test usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45294f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "first_noti_sender = list(session_notis.values())[0][0]\n",
    "first_noti_sender(\"Test message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f987f6",
   "metadata": {},
   "source": [
    "### Chat websockets\n",
    "\n",
    "When connecting to websockets for chat, this function should:\n",
    "\n",
    "- Extract the new and all previous chat history  \n",
    "- Prompt & get answers from ChatGPT from all these messages  \n",
    "- Return a new ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8045ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# On websocket disconnect, remove the session ID from the session messages and tools\n",
    "def chat_disconnect(ws):\n",
    "    \"\"\"Remove session ID from session messages and tools on websocket disconnect\"\"\"\n",
    "    session_id = ws.scope.get(\"session_id\")\n",
    "    if session_id in session_messages:\n",
    "        del session_messages[session_id]\n",
    "    if session_id in session_tools:\n",
    "        del session_tools[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c803cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# The chatbot websocket handler\n",
    "@app.ws('/wschat', disconn=chat_disconnect)\n",
    "async def wschat(ws, msg: str, send, session_id: str):\n",
    "    # Initialize the session\n",
    "    session_id = init_session(session_id=session_id)\n",
    "\n",
    "    # Set the session ID in the websocket scope\n",
    "    ws.scope[\"session_id\"] = session_id\n",
    "\n",
    "    # Set up the global variables\n",
    "    global session_tools\n",
    "    global execute_handler\n",
    "    \n",
    "    # Create chat messages from the provided contents and roles\n",
    "    messages = session_messages.get(session_id, [])\n",
    "    if len(messages) == 0:\n",
    "        messages.append(\n",
    "            form_msg(\n",
    "                \"system\", \n",
    "\"You are a helpful assistant. Use the supplied tools to assist the user. \\\n",
    "If asked to show or display an image or plot, do it by embedding its path starting with \\\n",
    "`../data/<filename>` in Markdown syntax. \\\n",
    "When asked to monitor or notify about a process, do not operate the condition but instead\\\n",
    "start a notification stream to monitor the process and \\\n",
    "use the available tools to stop stream or send notifications. \\\n",
    "By default, stop stream after one notification sent.\"))\n",
    "    messages.append(form_msg(\"user\", msg))\n",
    "    await send(\n",
    "        Div(ChatMessage(\n",
    "            messages[-1][\"content\"],\n",
    "            messages[-1][\"role\"] == \"user\"), \n",
    "        hx_swap_oob='beforeend', id=\"chatlist\"))\n",
    "    \n",
    "    await send(ChatInput())  # Clear the input field\n",
    "    \n",
    "    # Add the user's message to the chat history\n",
    "    complete(messages, session_tools[session_id])\n",
    "    await send(Div(ChatMessage(\n",
    "            messages[-1][\"content\"],\n",
    "            messages[-1][\"role\"] == \"user\"), hx_swap_oob='beforeend', id=\"chatlist\"))\n",
    "    \n",
    "    await send(Div(ToolPanel(session_id=session_id), hx_swap_oob='true', id='toollist'))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a6b79",
   "metadata": {},
   "source": [
    "### Static files\n",
    "\n",
    "In case the user needs to display images, serves files from directory `../data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3310edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Serve files from the 'data' directory\n",
    "@app.get(\"/data/{file_name:path}\")\n",
    "async def get_file(file_name: str):\n",
    "    \"\"\"Serve files dynamically from the 'data' directory.\"\"\"\n",
    "    data_path = os.getenv(\"LLMCAM_DATA\", \"../data\")\n",
    "    file_path = Path(data_path) / file_name\n",
    "    if file_path.exists():\n",
    "        return FileResponse(file_path)\n",
    "    return {\"error\": f\"File '{file_name}' not found\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3dc6cb",
   "metadata": {},
   "source": [
    "## Runner\n",
    "\n",
    "In addition to the main app, an utility function is implemented to run the app just by importing and executing this function to a Python file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "def llmcam_chatbot(\n",
    "        host=\"0.0.0.0\",  # The host to listen on\n",
    "        port=5001,  # The port to listen on\n",
    "    ):\n",
    "    # Import app from chat_ui base module\n",
    "    from llmcam.chat_ui import app\n",
    "\n",
    "    # Initialize session tools and execute handler\n",
    "    session_tools = {}\n",
    "    globals()[\"session_tools\"] = session_tools\n",
    "\n",
    "    def execute_handler(\n",
    "        function_name: str,  # Name of the function to execute\n",
    "        session_id: str,  # Session ID to use\n",
    "        **kwargs,  # Additional arguments to pass to the function\n",
    "    ):\n",
    "        tools = session_tools[session_id]\n",
    "        return execute_handler_core(tools, function_name, **kwargs)\n",
    "    \n",
    "    globals()[\"execute_handler\"] = execute_handler\n",
    "    \n",
    "    server = uvicorn.Server(uvicorn.Config(app, host=host, port=port))\n",
    "    async def async_run_server(server): await server.serve()\n",
    "    asyncio.run(async_run_server(server))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21e80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L300){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### llmcam_chatbot\n",
       "\n",
       ">      llmcam_chatbot (host='0.0.0.0', port=5001)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| host | str | 0.0.0.0 | The host to listen on |\n",
       "| port | int | 5001 | The port to listen on |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L300){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### llmcam_chatbot\n",
       "\n",
       ">      llmcam_chatbot (host='0.0.0.0', port=5001)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| host | str | 0.0.0.0 | The host to listen on |\n",
       "| port | int | 5001 | The port to listen on |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(llmcam_chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497fe71",
   "metadata": {},
   "source": [
    "For running while testing with Jupyter notebook, use the `JupyUvi` in `fasthtml` to run in separate thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e1b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=mwN6l3O1MNI\n",
      "[youtube] mwN6l3O1MNI: Downloading webpage\n",
      "[youtube] mwN6l3O1MNI: Downloading ios player API JSON\n",
      "[youtube] mwN6l3O1MNI: Downloading mweb player API JSON\n",
      "[youtube] mwN6l3O1MNI: Downloading m3u8 information\n",
      "[youtube] mwN6l3O1MNI: Downloading m3u8 information\n",
      "\n",
      "image 1/1 /home/nghivo/tinyMLaaS/llmcam/../data/cap_2024.12.03_00:49:38_None.jpg: 384x640 9 cars, 1 traffic light, 64.5ms\n",
      "Speed: 3.0ms preprocess, 64.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "from fasthtml.jupyter import *\n",
    "\n",
    "server = JupyUvi(app=app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "server.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b67952f-5064-48ad-a0f5-a141be065b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
