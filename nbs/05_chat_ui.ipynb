{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f0ff07-13fe-4ebe-970d-4848f7462e09",
   "metadata": {},
   "source": [
    "# chat UI in fastHTML\n",
    "\n",
    "> chat UI implemented in fastHTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2b36b977-f531-4d05-af7a-1761ef5d2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp chat_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ddd185b2-ec84-46d1-8474-9038ee3eb232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d57e4",
   "metadata": {},
   "source": [
    "## Response generation\n",
    "\n",
    "For our first MVP, response generation mostly concern with GPT models answering generic questions and using a single tool for capturing and extracting information from a Youtube Livestream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bfe07c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Importing openai and our custom functions\n",
    "import openai\n",
    "import json\n",
    "import ast\n",
    "import inspect\n",
    "\n",
    "from typing import Optional, Union\n",
    "from types import NoneType\n",
    "from llmcam.ytlive import capture_youtube_live_frame\n",
    "from llmcam.gpt4v import ask_gpt4v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db9267",
   "metadata": {},
   "source": [
    "### `extract_live_info` Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e7025792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_live_info(\n",
    "        link: Optional[str] = None  # YouTube Live link\n",
    "    ) -> dict:  # The extracted information\n",
    "    \"\"\"Extarct information from a YouTube Live\"\"\"\n",
    "    if link:\n",
    "        image = capture_youtube_live_frame(link)\n",
    "    else:\n",
    "        image = capture_youtube_live_frame()\n",
    "    \n",
    "    return ask_gpt4v(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47023d7",
   "metadata": {},
   "source": [
    "One additional utility to extract parameter descriptions from a funcion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "446262e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Extract parameter comments from the function\n",
    "def extract_parameter_comments(func):\n",
    "    \"\"\"Extract comments for function arguments\"\"\"\n",
    "    # Get the source code of the function\n",
    "    source = inspect.getsource(func)\n",
    "    # Parse the source code into an AST\n",
    "    tree = ast.parse(source)\n",
    "    \n",
    "    # Extract comments for function arguments\n",
    "    comments = {}\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef) and node.name == func.__name__:\n",
    "            # Get arguments and comments in the function\n",
    "            for arg in node.args.args:\n",
    "                arg_name = arg.arg\n",
    "                # Check if there's an inline comment associated with the argument\n",
    "                if arg.end_lineno and arg.col_offset:\n",
    "                    # Loop through the source code lines to find the comment\n",
    "                    lines = source.splitlines()\n",
    "                    for line in lines:\n",
    "                        if line.strip().startswith(f\"{arg_name}:\") and \"#\" in line:\n",
    "                            comment = line.split(\"#\")[1].strip()\n",
    "                            comments[arg_name] = comment\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55709492",
   "metadata": {},
   "source": [
    "Test usage with extract live function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fd528ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'link': 'YouTube Live link'}\n"
     ]
    }
   ],
   "source": [
    "# Extract parameter comments\n",
    "param_comments = extract_parameter_comments(extract_live_info)\n",
    "print(param_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b0fec5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test the function\n",
    "assert param_comments['link'] == \"YouTube Live link\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f866eb07",
   "metadata": {},
   "source": [
    "### Utilities for GPT Function calling\n",
    "\n",
    "We can use dynamic utilities functions to integrate this to GPT Function calling:  \n",
    "\n",
    "- Parameter converter: convert Python parameter types into schema accepted formats\n",
    "- Schema generator: extract function information into tool schema to bet set for GPT\n",
    "- Function execution: execute function dynamically based on function names and input arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3f3e5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def param_converter(\n",
    "        param_type,  # The type of the parameter\n",
    "        description  # The description of the parameter\n",
    "    ) -> dict:  # The converted parameter\n",
    "    \"\"\"Convert parameter types to acceptable types for tool schema\"\"\"\n",
    "    simple_types = {\n",
    "        str: \"string\",\n",
    "        int: \"number\",\n",
    "        float: \"number\",\n",
    "        bool: \"boolean\",\n",
    "    }\n",
    "    if param_type in simple_types:\n",
    "        return { \"type\": simple_types[param_type], \"description\": description }\n",
    "    elif param_type == NoneType:\n",
    "        return { \"type\": \"null\", \"description\": \"A default value will be automatically used.\" }\n",
    "    \n",
    "    if hasattr(param_type, '__origin__') and param_type.__origin__ == Union:\n",
    "        # Recursively convert the types\n",
    "        descriptions = description.split(\" or \")\n",
    "        subtypes = param_type.__args__\n",
    "        if len(subtypes) > len(descriptions):\n",
    "            descriptions = descriptions + [\"A description is not provided\"] * (len(subtypes) - len(descriptions))\n",
    "\n",
    "        return {\n",
    "            \"anyOf\": [param_converter(subtype, desc) for subtype, desc in zip(subtypes, descriptions)]\n",
    "        }\n",
    "    return { \"type\": \"string\", \"description\": description }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b0cf68",
   "metadata": {},
   "source": [
    "Test usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3d416743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"anyOf\": [\n",
      "    {\n",
      "      \"type\": \"string\",\n",
      "      \"description\": \"YouTube Live link\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"null\",\n",
      "      \"description\": \"A default value will be automatically used.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "param_schema = param_converter(Optional[str], \"YouTube Live link\")\n",
    "print(json.dumps(param_schema, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c3b8ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test the function\n",
    "assert param_schema == { \"anyOf\": [\n",
    "        {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"YouTube Live link\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"null\",\n",
    "            \"description\": \"A default value will be automatically used.\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9bd01075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def tool_schema(func):\n",
    "    \"\"\"Automatically generate a schema from its parameters and docstring\"\"\"\n",
    "    # Extract function name, docstring, and parameters\n",
    "    func_name = func.__name__\n",
    "    func_description = func.__doc__ or \"No description provided.\"\n",
    "    signature = inspect.signature(func)\n",
    "    \n",
    "    # Create parameters schema\n",
    "    parameters_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {},\n",
    "        \"required\": []\n",
    "    }\n",
    "    \n",
    "    # Populate properties and required fields\n",
    "    param_comments = extract_parameter_comments(func)\n",
    "    for param_name, param in signature.parameters.items():\n",
    "        param_type = param.annotation if param.annotation != inspect._empty else str\n",
    "        \n",
    "        # Add parameter to schema\n",
    "        parameters_schema[\"properties\"][param_name] = param_converter(\n",
    "            param_type, \n",
    "            param_comments.get(param_name, \"No description provided.\")\n",
    "        )\n",
    "        \n",
    "        # Mark as required if no default\n",
    "        if param.default == inspect.Parameter.empty:\n",
    "            parameters_schema[\"required\"].append(param_name)\n",
    "    \n",
    "    # Build final tool schema\n",
    "    tool_schema = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": func_name,\n",
    "                \"description\": func_description,\n",
    "                \"parameters\": parameters_schema,\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return tool_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e3da620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "tools = tool_schema(extract_live_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d7f8d028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "      \"name\": \"extract_live_info\",\n",
      "      \"description\": \"Extarct information from a YouTube Live\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"link\": {\n",
      "            \"anyOf\": [\n",
      "              {\n",
      "                \"type\": \"string\",\n",
      "                \"description\": \"YouTube Live link\"\n",
      "              },\n",
      "              {\n",
      "                \"type\": \"null\",\n",
      "                \"description\": \"A default value will be automatically used.\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"required\": []\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "print(json.dumps(tools, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "00ac11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test the function\n",
    "assert tools[0][\"function\"][\"name\"] == \"extract_live_info\"\n",
    "assert tools[0][\"function\"][\"description\"] == \"Extarct information from a YouTube Live\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "37b8d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Support functions to handle tool response,where res == response.choices[0].message\n",
    "def fn_name(res): return res.tool_calls[0].function.name\n",
    "def fn_args(res): return json.loads(res.tool_calls[0].function.arguments)    \n",
    "def fn_exec(res): return globals().get(fn_name(res))(**fn_args(res))\n",
    "def fn_result_content(res):\n",
    "    \"\"\"Create a content containing the result of the function call\"\"\"\n",
    "    content = dict()\n",
    "    content.update(fn_args(res))\n",
    "    content.update({fn_name(res): fn_exec(res)})\n",
    "    return json.dumps(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c39fb",
   "metadata": {},
   "source": [
    "### Response generator with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e59b377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_response(\n",
    "        message: str,  # New message frorm the user\n",
    "        history : list,  # Previous messages\n",
    "    ) -> list:  # The responses of GPT model\n",
    "    \"\"\"Generate a response from the messages\"\"\"\n",
    "    responses = []\n",
    "\n",
    "    def complete(role, content, tool_call_id=None):\n",
    "        \"Send completion request with messages, and save the response in messages again\"\n",
    "        responses.append({\n",
    "            \"role\":role, \n",
    "            \"content\":content, \n",
    "            \"tool_call_id\":tool_call_id\n",
    "        })\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\", \n",
    "            messages=history + responses, \n",
    "            tools=tools\n",
    "        )\n",
    "        res = response.choices[0].message\n",
    "        responses.append(res.to_dict())\n",
    "        if res.to_dict().get('tool_calls'):\n",
    "            complete(role=\"tool\", content=fn_result_content(res), tool_call_id=res.tool_calls[0].id)\n",
    "\n",
    "    complete(\"user\", message)\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a46f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=LMZQ7eFhm58\n",
      "[youtube] LMZQ7eFhm58: Downloading webpage\n",
      "[youtube] LMZQ7eFhm58: Downloading ios player API JSON\n",
      "[youtube] LMZQ7eFhm58: Downloading mweb player API JSON\n",
      "[youtube] LMZQ7eFhm58: Downloading m3u8 information\n",
      "[youtube] LMZQ7eFhm58: Downloading m3u8 information\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"Yes, please use the default link.\",\n",
      "    \"tool_call_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"content\": null,\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\",\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_WNKVSnuYqt9X86YZfAfa7lj6\",\n",
      "        \"function\": {\n",
      "          \"arguments\": \"{\\\"link\\\":null}\",\n",
      "          \"name\": \"extract_live_info\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"tool\",\n",
      "    \"content\": \"{\\\"link\\\": null, \\\"extract_live_info\\\": {\\\"timestamp\\\": \\\"2024-01-11T01:15:45\\\", \\\"location\\\": null, \\\"dimensions\\\": {\\\"width\\\": 1280, \\\"height\\\": 720}, \\\"buildings\\\": {\\\"number_of_buildings\\\": 15, \\\"building_height_range\\\": \\\"2-10 stories\\\"}, \\\"cranes\\\": {\\\"number_of_cranes\\\": 2}, \\\"lighting\\\": {\\\"time_of_day\\\": \\\"night\\\", \\\"artificial_lighting\\\": \\\"prominent\\\"}, \\\"people\\\": {\\\"approximate_number\\\": 0}, \\\"vehicles\\\": {\\\"number_of_vehicles\\\": 0}, \\\"landmarks\\\": {\\\"number_of_visible_landmarks\\\": 1}, \\\"sky\\\": {\\\"visible\\\": true, \\\"light_conditions\\\": \\\"dark\\\"}}}\",\n",
      "    \"tool_call_id\": \"call_WNKVSnuYqt9X86YZfAfa7lj6\"\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"The extracted information from the default YouTube Live link is as follows:\\n\\n- **Timestamp:** January 11, 2024, 01:15:45 (UTC time)\\n- **Location:** Not specified\\n- **Dimensions:** 1280 x 720 pixels\\n- **Buildings:** 15 buildings are identified, ranging from 2 to 10 stories in height\\n- **Cranes:** There are 2 cranes visible\\n- **Lighting:** It's nighttime with prominent artificial lighting\\n- **People:** Approximately 0 people are visible\\n- **Vehicles:** No vehicles are visible\\n- **Landmarks:** 1 visible landmark\\n- **Sky:** The sky is visible, with dark light conditions\\n\\nLet me know if you need more information or have further questions!\",\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "example = generate_response(\n",
    "    \"Yes, please use the default link.\",\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Extract information from a YouTube Live\",\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"Please provide the YouTube Live link you would like to extract information from, or let me know if you'd like to use a default link.\",\n",
    "            \"refusal\": None,\n",
    "            \"role\": \"assistant\"\n",
    "        }\n",
    "    ])\n",
    "print(json.dumps(example, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17c22c",
   "metadata": {},
   "source": [
    "## Chat App initialization\n",
    "\n",
    "Start by creating the chat application with `FastHTML`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6714c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import uvicorn\n",
    "import importlib.util\n",
    "from fasthtml.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2a5b1df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Set up the app, including daisyui and tailwind for the chat component\n",
    "hdrs = (picolink, Script(src=\"https://cdn.tailwindcss.com\"),\n",
    "        Link(rel=\"stylesheet\", href=\"https://cdn.jsdelivr.net/npm/daisyui@4.11.1/dist/full.min.css\"))\n",
    "app = FastHTML(hdrs=hdrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0211a31",
   "metadata": {},
   "source": [
    "## Chat components\n",
    "\n",
    "Basic chat UI components can include Chat Message and a Chat Input. For a Chat Message, the important attributes are the actual message (str) and the role of the message owner (user - boolean value whether the owner is the user, not the AI assistant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2a6c7f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Chat message component (renders a chat bubble)\n",
    "def ChatMessage(\n",
    "        msg: str,  # Message to display\n",
    "        user: bool  # Whether the message is from the user or assistant\n",
    "    ):  # Returns a Div containing the chat bubble\n",
    "    paragraphs = msg.split(\"\\n\")\n",
    "    # Set class to change displayed style of bubble\n",
    "    bubble_class = \"chat-bubble-primary\" if user else 'chat-bubble-secondary'\n",
    "    chat_class = \"chat-end\" if user else 'chat-start'\n",
    "    return  Div(cls=f\"chat {chat_class}\")(\n",
    "                Div('User' if user else 'Assistant', cls=\"chat-header\"),\n",
    "                Div(\n",
    "                    *[P(p, style=f\"color: {'black' if user else 'white'};\") for p in paragraphs], \n",
    "                    cls=f\"chat-bubble {bubble_class}\", \n",
    "                    style=f\"background-color: {'#03fcad' if user else '#025238'};\"),\n",
    "                Hidden(msg, name=\"messages\"),  # Hidden field for submitting past messages to form\n",
    "                Hidden(\"user\" if user else \"assistant\", name=\"roles\")  # Hidden field for submitting corresponding owners\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "61d96926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L21){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChatMessage\n",
       "\n",
       ">      ChatMessage (msg:str, user:bool)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| msg | str | Message to display |\n",
       "| user | bool | Whether the message is from the user or assistant |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L21){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChatMessage\n",
       "\n",
       ">      ChatMessage (msg:str, user:bool)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| msg | str | Message to display |\n",
       "| user | bool | Whether the message is from the user or assistant |"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChatMessage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc84d14",
   "metadata": {},
   "source": [
    "For the chat input, set the name for submitting a new message via form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8b6bbd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# The input field for the user message. Also used to clear the\n",
    "# input field after sending a message via an OOB swap\n",
    "def ChatInput():  # Returns an input field for the user message\n",
    "    return Input(name='msg', id='msg-input', placeholder=\"Type a message\",\n",
    "                 cls=\"input input-bordered w-full rounded-l-2xl bg-stone-800\", \n",
    "                 hx_swap_oob='true'  # Re-render the element to remove submitted message\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ad8a8814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L39){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChatInput\n",
       "\n",
       ">      ChatInput ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L39){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChatInput\n",
       "\n",
       ">      ChatInput ()"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChatInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986a51e",
   "metadata": {},
   "source": [
    "### Action Buttons\n",
    "\n",
    "Simple actions for creating a new message from the user side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "86cba3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ActionButton(\n",
    "        content: str  # Text to display on the button\n",
    "    ):  # Returns a button with the given content\n",
    "\n",
    "    return Form(\n",
    "        hx_post=\"/\",\n",
    "        hx_target=\"#chatlist\",\n",
    "        hx_swap=\"beforeend\",  # Location: just before the end of element\n",
    "    )(\n",
    "        Hidden(content, name=\"msg\"),\n",
    "        Button(content, cls=\"btn btn-secondary\")\n",
    "    )\n",
    "\n",
    "def ActionPanel():  # Returns a panel of action buttons\n",
    "    return Div(\n",
    "        ActionButton(\"Do something\"),\n",
    "        ActionButton(\"A different action\"),\n",
    "        cls=\"flex flex-row h-fit px-24 gap-4 pt-4\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fe59ea66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ActionButton\n",
       "\n",
       ">      ActionButton (content:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| content | str | Text to display on the button |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ActionButton\n",
       "\n",
       ">      ActionButton (content:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| content | str | Text to display on the button |"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ActionButton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ef9f47bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L56){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ActionPanel\n",
       "\n",
       ">      ActionPanel ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L56){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ActionPanel\n",
       "\n",
       ">      ActionPanel ()"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ActionPanel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174209ca",
   "metadata": {},
   "source": [
    "## Router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b9a76",
   "metadata": {},
   "source": [
    "### Home page\n",
    "The home page should contain our message list and the Chat Input. The main page can be extracted by accessing the index (root) endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3371d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@app.get('/')\n",
    "def index():\n",
    "    sidebar = Div(\n",
    "        H1(\"Conversations\"),\n",
    "        cls=\"w-[30vw] bg-stone-800\"\n",
    "    )\n",
    "    page =  Div(cls=\"w-full flex flex-col p-0\")(\n",
    "        ActionPanel(),\n",
    "        Form(\n",
    "            hx_post=\"/\",  # Operation: some POST endpoint with function `send` \n",
    "            hx_target=\"#chatlist\",  # Target: element with ID 'chatlist'\n",
    "            hx_swap=\"beforeend\",  # Location: just before the end of element\n",
    "            cls=\"w-full flex flex-col px-24 h-[90vh]\"\n",
    "        )(\n",
    "            # The chat list\n",
    "            Div(id=\"chatlist\", cls=\"chat-box overflow-y-auto flex-1 w-full mt-10\")(\n",
    "                # One initial message from AI assistant\n",
    "                ChatMessage(\"Hello! I'm a chatbot. How can I help you today?\", False),\n",
    "            ),\n",
    "            # Input form\n",
    "            Div(cls=\"h-fit mb-5 mt-5 flex space-x-2 mt-2\")(\n",
    "                Group(\n",
    "                    ChatInput(), \n",
    "                    Button(\"Send\", cls=\"btn btn-primary rounded-r-2xl\", style=\"background-color: #03fcad;\"))\n",
    "            )\n",
    "        )   \n",
    "    )\n",
    "    return Main(\n",
    "        sidebar,\n",
    "        page, \n",
    "        data_theme=\"forest\", \n",
    "        cls=\"h-[100vh] w-full relative flex flex-row items-stretch overflow-hidden transition-colors z-0 p-0\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f987f6",
   "metadata": {},
   "source": [
    "### Form submission\n",
    "\n",
    "At submission, this function should:\n",
    "\n",
    "- Extract the new and all previous chat history  \n",
    "- Prompt & get answers from ChatGPT from all these messages  \n",
    "- Return a new ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c803cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=LMZQ7eFhm58\n",
      "[youtube] LMZQ7eFhm58: Downloading webpage\n",
      "[youtube] LMZQ7eFhm58: Downloading ios player API JSON\n",
      "[youtube] LMZQ7eFhm58: Downloading mweb player API JSON\n",
      "[youtube] LMZQ7eFhm58: Downloading m3u8 information\n",
      "[youtube] LMZQ7eFhm58: Downloading m3u8 information\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=LMZQ7eFhm58\n",
      "[youtube] LMZQ7eFhm58: Downloading webpage\n",
      "[youtube] LMZQ7eFhm58: Downloading ios player API JSON\n",
      "[youtube] LMZQ7eFhm58: Downloading mweb player API JSON\n",
      "[youtube] LMZQ7eFhm58: Downloading m3u8 information\n",
      "[youtube] LMZQ7eFhm58: Downloading m3u8 information\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "# Handle the form submission\n",
    "@app.post('/')\n",
    "def send(msg: str, messages: list[str] = None, roles: list[str] = None):\n",
    "    if not messages: messages = []\n",
    "    if not roles: roles = []\n",
    "\n",
    "    history = [ {\"role\": role, \"content\": message} for role, message in zip(roles, messages) ]\n",
    "    \n",
    "    # Add the user's message to the chat history\n",
    "    responses = generate_response(msg, history)\n",
    "    chat_messages = [\n",
    "        ChatMessage(res['content'], res['role'] == 'user') for res in responses if 'content' in res \\\n",
    "            if res['role'] in ['user', 'assistant'] and res['content'] is not None\n",
    "    ]\n",
    "    \n",
    "    return (*chat_messages,\n",
    "            ChatInput()) # And clear the input field via an OOB swap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3dc6cb",
   "metadata": {},
   "source": [
    "## Runner\n",
    "\n",
    "In addition to the main app, an utility function is implemented to run the app just by importing and executing this function to a Python file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e7a8309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def llmcam_chatbot(\n",
    "        package_name=\"ninjalabo.llmcam\",  # The installed package name\n",
    "        module_name=\"chat_ui\",  # The module containing the FastAPI app\n",
    "        app_variable=\"app\",  # The FastAPI app variable name\n",
    "        host=\"0.0.0.0\",  # The host to listen on\n",
    "        port=5001,  # The port to listen on\n",
    "        **uvicorn_kwargs  # Additional keyword arguments for uvicorn\n",
    "    ):\n",
    "    \"Find and run the FastAPI app in the specified module within the given package.\"\n",
    "    # Construct the full module path (e.g., 'llmcam.chat_ui')\n",
    "    full_module_path = f\"{package_name.split('.')[-1]}.{module_name}\"\n",
    "\n",
    "    # Check if the module exists in the installed package\n",
    "    try:\n",
    "        spec = importlib.util.find_spec(full_module_path)\n",
    "        if spec is None:\n",
    "            print(f\"Module '{full_module_path}' not found in package '{package_name}'.\")\n",
    "            return\n",
    "        # Dynamically run the Uvicorn server\n",
    "        uvicorn.run(f\"{full_module_path}:{app_variable}\", host=host, port=port, **uvicorn_kwargs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error running the app: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2d21e80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L118){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### llmcam_chatbot\n",
       "\n",
       ">      llmcam_chatbot (package_name='ninjalabo.llmcam', module_name='chat_ui',\n",
       ">                      app_variable='app', host='0.0.0.0', port=5001,\n",
       ">                      **uvicorn_kwargs)\n",
       "\n",
       "*Find and run the FastAPI app in the specified module within the given package.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| package_name | str | ninjalabo.llmcam | The installed package name |\n",
       "| module_name | str | chat_ui | The module containing the FastAPI app |\n",
       "| app_variable | str | app | The FastAPI app variable name |\n",
       "| host | str | 0.0.0.0 | The host to listen on |\n",
       "| port | int | 5001 | The port to listen on |\n",
       "| uvicorn_kwargs |  |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/chat_ui.py#L118){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### llmcam_chatbot\n",
       "\n",
       ">      llmcam_chatbot (package_name='ninjalabo.llmcam', module_name='chat_ui',\n",
       ">                      app_variable='app', host='0.0.0.0', port=5001,\n",
       ">                      **uvicorn_kwargs)\n",
       "\n",
       "*Find and run the FastAPI app in the specified module within the given package.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| package_name | str | ninjalabo.llmcam | The installed package name |\n",
       "| module_name | str | chat_ui | The module containing the FastAPI app |\n",
       "| app_variable | str | app | The FastAPI app variable name |\n",
       "| host | str | 0.0.0.0 | The host to listen on |\n",
       "| port | int | 5001 | The port to listen on |\n",
       "| uvicorn_kwargs |  |  |  |"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(llmcam_chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497fe71",
   "metadata": {},
   "source": [
    "For running while testing with Jupyter notebook, use the `JupyUvi` in `fasthtml` to run in separate thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5d2e1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from fasthtml.jupyter import *\n",
    "\n",
    "server = JupyUvi(app=app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c95a1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "server.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4b67952f-5064-48ad-a0f5-a141be065b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasthtml-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
