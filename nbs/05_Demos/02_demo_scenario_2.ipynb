{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Scenario 2\n",
    "> Validate Demonstrate Scenario 2 on a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "from llmcam.utils.downloader import *\n",
    "from llmcam.vision.dtcam import *\n",
    "from llmcam.utils.file_manager import *\n",
    "from llmcam.core.fn_to_fc import *\n",
    "from llmcam.utils.store import *\n",
    "from llmcam.vision.yolo import *\n",
    "from llmcam.vision.plotting import *\n",
    "from llmcam.vision.gpt4v import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def send_notification(\n",
    "        msg: str  # The message to send\n",
    "    ):\n",
    "    \"\"\"Send a notification\"\"\"\n",
    "    global messages\n",
    "    messages.append(form_msg(\"assistant\", f\"Notification: {msg}\"))\n",
    "    complete(messages, tools)\n",
    "    return msg\n",
    "\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "def start_notifications_stream(\n",
    "    messages: list  # Previous conversation with the user\n",
    "):\n",
    "    \"\"\"Start the notifications stream and monitoring. At the end of the stream, notify users about the results.\"\"\"\n",
    "    global tools\n",
    "\n",
    "    # Add sending notification to tool schema\n",
    "    subtools = [ tool for tool in tools if tool['function']['name'] != 'start_notifications_stream' ]\n",
    "    subtools.append(tool_schema(send_notification, 'send_notification'))\n",
    "\n",
    "    # Copy the messages to avoid modifying the original list\n",
    "    messages = [ message for message in messages ]\n",
    "\n",
    "    # Define the functionality to use\n",
    "    def monitoring_loop():\n",
    "        for _ in range(5):  \n",
    "            time.sleep(10)  \n",
    "\n",
    "            # Ask GPT if the condition is met\n",
    "            messages.append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Evaluate the data. Does it satisfy the condition stated by the user? When the condition is met, send a message to user only if the notification has not been sent before! \"\n",
    "            })\n",
    "            complete(messages, tools=subtools)\n",
    "\n",
    "    # Start the notifications stream\n",
    "    t = Thread(target=monitoring_loop)\n",
    "    t.start()\n",
    "\n",
    "    return 'Notifications stream started'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "tools = []\n",
    "def execute_handler(function_name, **kwargs):\n",
    "    execute_handler_core(tools, function_name, **kwargs)\n",
    "\n",
    "tools.extend([handler_schema(function, service_name=\"toolbox_handler\", fixup=execute_handler) for function in [\n",
    "        add_api_tools,\n",
    "        add_function_tools,\n",
    "        remove_tools,\n",
    "        capture_youtube_live_frame_and_save,\n",
    "        ask_gpt4v_about_image_file,\n",
    "        list_image_files,\n",
    "        list_detection_files,\n",
    "        plot_object,\n",
    "        detect_objects\n",
    "    ]])\n",
    "\n",
    "tools.append(tool_schema(start_notifications_stream, 'notification'))\n",
    "tools[-1]['function']['parameters'] = {\n",
    "    'type': 'object',\n",
    "    'properties': {\n",
    "        'messages': {\n",
    "            'type': 'array',\n",
    "            'items': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'role': {\n",
    "                        'type': 'string',\n",
    "                        'enum': ['user', 'tool', 'system', 'assistant']\n",
    "                    },\n",
    "                    'content': {\n",
    "                        'type': 'string'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[31mSystem:\u001b[0m\n",
      "You are a helpful system administrator. Use the supplied tools to help the user.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "What can LLMCAM do?\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "LLMCAM is a tool that captures images from YouTube Live streams and performs image analysis tasks.\n",
      "Here's what it can do:  - **Capture YouTube Live Frame**: It can capture a JPEG file from a YouTube\n",
      "Live stream and save it in a data directory for further processing.    - **List Captured Images**:\n",
      "It can list all captured image files, which are named based on the date, time, and place of capture.\n",
      "- **List Detection Files**: It can list all detection image files that start with \"detection_\" in\n",
      "their name.  - **Object Detection**: It can run YOLO (You Only Look Once) object detection on an\n",
      "input image to identify objects present.  - **Plot Object Occurrences**: It can generate a bar plot\n",
      "showing the number of instances of a specified object detected in a list of images.  - **Ask GPT-4V\n",
      "about Images**: It can use GPT-4V to provide quantitative information about an image file.  -\n",
      "**Start Notifications Stream**: It can start the notifications stream and monitoring, and notify\n",
      "users about the results at the end of the stream.   These capabilities allow for comprehensive\n",
      "analysis and visualization of visual data from live streams.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "Here is the live feed for Santa Claus Village: https://www.youtube.com/watch?v=Cp4RRAEgpeU to\n",
      "capture\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "I have captured an image frame from the Santa Claus Village live feed and saved it as\n",
      "`cap_2024.11.26_09:38:40_Santa Claus Village.jpg`.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "How many people are there currently?\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "The image from the Santa Claus Village live feed shows 9 people currently present.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "Show me the image path of your detection.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "The detection was performed on the image located at the path: `../data/cap_2024.11.26_09:38:40_Santa\n",
      "Claus Village.jpg`.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "That is the image, not the detection file. I want the detection path.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "The detection file for the image taken at Santa Claus Village can be found at the path:\n",
      "`../data/detection_cap_2024.11.26_09:38:40_Santa Claus Village.jpg`.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "List the images captured at Santa Claus Village during yesterday and today.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "Here are the images captured from Santa Claus Village during yesterday and today:  - Yesterday:   -\n",
      "`../data/cap_2024.11.25_10:22:58_Santa Claus Village.jpg`   - `../data/cap_2024.11.25_10:53:45_Santa\n",
      "Claus Village.jpg`   - `../data/cap_2024.11.25_10:44:12_Santa Claus Village.jpg`  - Today:   -\n",
      "`../data/cap_2024.11.26_09:32:54_Santa Claus Village.jpg`   - `../data/cap_2024.11.26_09:38:40_Santa\n",
      "Claus Village.jpg`\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "Plot the number of people in those images using YOLO only.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "The bar plot showing the number of people detected in the images from Santa Claus Village using YOLO\n",
      "has been created. You can view the plot at the following path: `../data/object_count_bar_plot.png`.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "Plot the number of people in those images using YOLO and GPT.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "The bar plot showing the number of people detected in the images from Santa Claus Village using both\n",
      "YOLO and GPT has been created. You can view the plot at the following path:\n",
      "`../data/object_count_bar_plot.png`.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "Monitor the live feed at Santa Claus Village (https://www.youtube.com/watch?v=Cp4RRAEgpeU) and\n",
      "notify me when there are fewer than 20 people.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "The live feed at Santa Claus Village is now being monitored. You will be notified when there are\n",
      "fewer than 20 people detected.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "Notification: There are currently fewer than 20 people at Santa Claus Village.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "If you have any further requests or need additional assistance, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "messages = form_msgs([\n",
    "    (\"system\", \"You are a helpful system administrator. Use the supplied tools to help the user.\"),\n",
    "    (\"user\", \"What can LLMCAM do?\")\n",
    "])\n",
    "# messages.append(form_msg(\"user\", \"Here is the live feed for Santa Claus Village: https://www.youtube.com/watch?v=Cp4RRAEgpeU to capture\"))\n",
    "# messages.append(form_msg(\"user\", \"How many people are there currently?\"))\n",
    "# messages.append(form_msg(\"user\", \"Show me the image path of your detection.\"))\n",
    "# messages.append(form_msg(\"user\", \"That is the image, not the detection file. I want the detection path.\"))\n",
    "# messages.append(form_msg(\"user\", \"List the images captured at Santa Claus Village during yesterday and today.\"))\n",
    "# messages.append(form_msg(\"user\", \"Plot the number of people in those images using YOLO and GPT.\"))\n",
    "# messages.append(form_msg(\"user\", \"Monitor the live feed at Santa Claus Village (https://www.youtube.com/watch?v=Cp4RRAEgpeU) and notify me when there are fewer than 20 people.\"))\n",
    "complete(messages, tools)\n",
    "print_msgs(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. User: What Function Calls (FCs) do you have?\n",
    "2. Assistant: I can monitor YouTube Live feeds and integrate with various services to provide insights and notifications.\n",
    "3. User: Here’s the YouTube Live feed for Santa Claus Village.\n",
    "4. Assistant: The YouTube Live feed for Santa Claus Village has been registered.\n",
    "5. User: How many people are currently there?\n",
    "6. Assistant: There are currently 52 people at Santa Claus Village.\n",
    "7. User: Plot the change in the number of people at Santa Claus Village over the last 3 hours.\n",
    "8. Assistant: [Generates and displays a bar chart showing the trend in people count over the last 3 hours.]\n",
    "9. User: Notify me if there are fewer than 10 people.\n",
    "10. Assistant: Notification rule set. I’ll alert you when the number of people at Santa Claus Village drops below 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
