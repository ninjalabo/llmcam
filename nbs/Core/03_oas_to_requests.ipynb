{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d8c4c4-0bc0-488b-a1a4-edd3c47481f6",
   "metadata": {},
   "source": [
    "# OAS->requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8257ad-690a-4ec4-93d4-c78dc561401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core.oas_to_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e912d-60a9-4e23-a9d5-35f78140cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7918e-55d3-4bfa-a5fb-05f9513b989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import json\n",
    "import yaml\n",
    "import copy\n",
    "import re\n",
    "from typing import Callable, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12becbb4",
   "metadata": {},
   "source": [
    "## OAS inspection\n",
    "\n",
    "This implementation focuses on DigiTraffic with its OpenAPI specification file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56306b-1233-491c-ae16-88ddef50c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "BASE_URL = \"https://tie.digitraffic.fi\"\n",
    "\n",
    "# Download a file from a URL\n",
    "def download_file(url, dest_file):\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    with open(dest_file, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "\n",
    "# Define the OpenAPI file path\n",
    "local_file = \"openapi.json\"\n",
    "\n",
    "# Download the OpenAPI JSON file if it doesn't exist\n",
    "openapi_url = f\"{BASE_URL}/swagger/openapi.json\"  # Update with the correct path\n",
    "if not os.path.exists(local_file):\n",
    "    download_file(openapi_url, local_file)\n",
    "\n",
    "# Load and parse the OpenAPI JSON file\n",
    "with open(local_file, 'r') as f:\n",
    "    spec_dict = json.load(f)\n",
    "oas = spec_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0a4ef",
   "metadata": {},
   "source": [
    "### Deep reference extraction\n",
    "\n",
    "In order to generate tool schemas, we need to resolve and flatten the references to `components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "MIME_TYPES = {\n",
    "    \"text\": [\n",
    "        \"plain\",\n",
    "        \"html\",\n",
    "        \"css\",\n",
    "        \"javascript\",\n",
    "        \"markdown\",\n",
    "        \"xml\",\n",
    "        \"csv\",\n",
    "        \"tab-separated-values\",\n",
    "        \"vcard\"\n",
    "    ],\n",
    "    \"application\": [\n",
    "        \"json\",\n",
    "        \"xml\",\n",
    "        \"javascript\",\n",
    "        \"x-www-form-urlencoded\",\n",
    "        \"multipart-form-data\",\n",
    "        \"pdf\",\n",
    "        \"zip\",\n",
    "        \"gzip\",\n",
    "        \"vnd.api+json\",\n",
    "        \"sql\",\n",
    "        \"octet-stream\",\n",
    "        \"ld+json\",\n",
    "        \"vnd.ms-excel\",\n",
    "        \"vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
    "        \"vnd.ms-word\",\n",
    "        \"vnd.openxmlformats-officedocument.wordprocessingml.document\",\n",
    "        \"vnd.ms-powerpoint\",\n",
    "        \"vnd.openxmlformats-officedocument.presentationml.presentation\",\n",
    "        \"x-tar\",\n",
    "        \"x-7z-compressed\",\n",
    "        \"vnd.android.package-archive\",\n",
    "        \"x-rar-compressed\",\n",
    "        \"x-bzip\",\n",
    "        \"x-bzip2\",\n",
    "        \"x-sh\",\n",
    "        \"x-java-archive\",\n",
    "        \"x-httpd-php\",\n",
    "        \"x-pkcs12\",\n",
    "        \"x-pkcs7-certificates\",\n",
    "        \"x-pkcs7-mime\",\n",
    "        \"x-pkcs7-signature\"\n",
    "    ],\n",
    "    \"image\": [\n",
    "        \"png\",\n",
    "        \"jpeg\",\n",
    "        \"gif\",\n",
    "        \"webp\",\n",
    "        \"svg+xml\",\n",
    "        \"bmp\",\n",
    "        \"tiff\",\n",
    "        \"x-icon\"\n",
    "    ],\n",
    "    \"audio\": [\n",
    "        \"mpeg\",\n",
    "        \"ogg\",\n",
    "        \"wav\",\n",
    "        \"webm\",\n",
    "        \"aac\",\n",
    "        \"midi\"\n",
    "    ],\n",
    "    \"video\": [\n",
    "        \"mp4\",\n",
    "        \"ogg\",\n",
    "        \"webm\",\n",
    "        \"x-msvideo\",\n",
    "        \"quicktime\"\n",
    "    ],\n",
    "    \"font\": [\n",
    "        \"ttf\",\n",
    "        \"otf\",\n",
    "        \"woff\",\n",
    "        \"woff2\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def retrieve_ref_parts(refs: str):\n",
    "    \"\"\"Retrieve the parts of a reference string\"\"\"\n",
    "    # Split the reference string into raw parts and initialize the parts list\n",
    "    raw_parts = refs.split(\"/\")\n",
    "    parts = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(raw_parts) - 1:\n",
    "        # Extract consecutive parts\n",
    "        first_part = raw_parts[i]\n",
    "        second_part = raw_parts[i + 1]\n",
    "\n",
    "        # Check if the parts are valid MIME types\n",
    "        if first_part in MIME_TYPES and second_part in MIME_TYPES[first_part]:\n",
    "            # Combine the MIME types\n",
    "            parts.append(f\"{first_part}/{second_part}\")\n",
    "            i += 2\n",
    "        else:\n",
    "            parts.append(first_part)\n",
    "            i += 1\n",
    "\n",
    "    # Add the last part if it is not a MIME type\n",
    "    if raw_parts[-2] not in MIME_TYPES or raw_parts[-1] not in MIME_TYPES[raw_parts[-2]]:\n",
    "        parts.append(raw_parts[-1])\n",
    "\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73699f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_refs(\n",
    "        oas: dict  # The OpenAPI schema\n",
    "    ) -> dict:  # The extracted references (flattened)\n",
    "    refs = copy.deepcopy(oas)\n",
    "    refs_list = set()\n",
    "    refs_locations = {}\n",
    "    refs_dependencies = {}\n",
    "\n",
    "    # Traverse the components section of the spec\n",
    "    for section, items in refs[\"components\"].items():\n",
    "        for item in items:\n",
    "            refs_list.add(f\"components/{section}/{item}\")\n",
    "            refs_locations[f\"components/{section}/{item}\"] = []\n",
    "            refs_dependencies[f\"components/{section}/{item}\"] = set()\n",
    "    \n",
    "    # Initialize the clean_refs set\n",
    "    clean_refs = refs_list.copy()\n",
    "\n",
    "    # Traverse the spec and extract the references\n",
    "    def traverse_location(obj, path=\"\"):\n",
    "        for key, value in obj.items():\n",
    "            if key == \"$ref\":\n",
    "                # Determine the root of the reference and remove it from the clean_refs set\n",
    "                ref_root = \"/\".join(path.split(\"/\")[:3])\n",
    "                clean_refs.discard(ref_root)\n",
    "\n",
    "                # Extract the sub reference and add the current path to the list of locations\n",
    "                sub_ref = value[2:]\n",
    "                refs_locations[sub_ref].append(path)\n",
    "\n",
    "                # Add the sub reference to the dependencies of the current reference\n",
    "                refs_dependencies[ref_root].add(sub_ref)\n",
    "\n",
    "            elif isinstance(value, dict):\n",
    "                # Recursively traverse the object\n",
    "                traverse_location(value, f\"{path}/{key}\")\n",
    "\n",
    "    traverse_location(refs[\"components\"], \"components\")\n",
    "\n",
    "    # Attach the reference objects to the locations\n",
    "    def attach_clean_refs():\n",
    "        for ref in clean_refs:\n",
    "            # Extract the reference object\n",
    "            ref_obj = refs\n",
    "            ref_paths = retrieve_ref_parts(ref)\n",
    "            for part in ref_paths:\n",
    "                ref_obj = ref_obj[part]\n",
    "\n",
    "            # Extract the locations where the reference is used\n",
    "            locations = refs_locations[ref]\n",
    "\n",
    "            # Attach the reference object to the locations\n",
    "            for location in locations:\n",
    "                location_parts = retrieve_ref_parts(location)\n",
    "\n",
    "                obj = refs\n",
    "                prev = None\n",
    "                for part in location_parts:\n",
    "                    prev = obj\n",
    "                    obj = obj[part]\n",
    "\n",
    "                prev[location_parts[-1]] = ref_obj\n",
    "\n",
    "            # Remove the reference from the dependencies\n",
    "            for dependency in refs_dependencies:\n",
    "                refs_dependencies[dependency].discard(ref)\n",
    "\n",
    "    # Check if there are any clean references\n",
    "    def check_clean_refs():\n",
    "        clean_refs = set()\n",
    "        for ref, dependencies in refs_dependencies.items():\n",
    "            if len(dependencies) == 0:\n",
    "                clean_refs.add(ref)\n",
    "        return clean_refs\n",
    "    \n",
    "    # Iterate until all references are attached or no progress is made\n",
    "    prev_nof_clean = None\n",
    "    while len(clean_refs) < len(refs_list) and prev_nof_clean != len(clean_refs):\n",
    "        prev_nof_clean = len(clean_refs)\n",
    "        attach_clean_refs()\n",
    "        clean_refs = check_clean_refs()\n",
    "\n",
    "    # Flatten the references\n",
    "    flatten_refs = {}\n",
    "    for section, items in refs[\"components\"].items():\n",
    "        for item in items:\n",
    "            flatten_refs[f\"#/components/{section}/{item}\"] = refs[\"components\"][section][item]\n",
    "\n",
    "    return flatten_refs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0d8cb",
   "metadata": {},
   "source": [
    "Examples from DigiTraffic components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d22c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: #/components/schemas/WeatherSensorValueHistoryDto ['type', 'properties']\n",
      "[00] type object\n",
      "[01] properties {\n",
      "    \"roadStationId\": {\n",
      "        \"type\": \"integer\",\n",
      "        \"description\": \"Road station id\",\n",
      "        \"format\": \"int64\"\n",
      "    },\n",
      "    \"sensorId\": {\n",
      "        \"type\": \"integer\",\n",
      "        \"description\": \"Sensor id\",\n",
      "        \"format\": \"int64\"\n",
      "    },\n",
      "    \"sensorValue\": {\n",
      "        \"type\": \"number\",\n",
      "        \"description\": \"Sensor value\",\n",
      "        \"format\": \"double\"\n",
      "    },\n",
      "    \"measured\": {\n",
      "        \"type\": \"string\",\n",
      "        \"format\": \"date-time\",\n",
      "        \"writeOnly\": true\n",
      "    },\n",
      "    \"reliability\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"Measurement reliability information\",\n",
      "        \"enum\": [\n",
      "            \"OK\",\n",
      "            \"SUSPICIOUS\",\n",
      "            \"FAULTY\",\n",
      "            \"UNKNOWN\"\n",
      "        ]\n",
      "    },\n",
      "    \"measuredTime\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"Value's measured date time\",\n",
      "        \"format\": \"date-time\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "refs = extract_refs(oas)\n",
    "for i, (ref, obj) in enumerate(list(refs.items())[:1]):\n",
    "    print(f\"Reference: {ref}\", list(obj.keys()))\n",
    "    for j, (k,v) in enumerate(obj.items()):\n",
    "        print(f\"[{i}{j}]\", k, json.dumps(v, indent=4) if k=='properties' else v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7e262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/oas_to_requests.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### extract_refs\n",
       "\n",
       ">      extract_refs (oas:dict)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| oas | dict | The OpenAPI schema |\n",
       "| **Returns** | **dict** | **The extracted references (flattened)** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/oas_to_requests.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### extract_refs\n",
       "\n",
       ">      extract_refs (oas:dict)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| oas | dict | The OpenAPI schema |\n",
       "| **Returns** | **dict** | **The extracted references (flattened)** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(extract_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02022cd",
   "metadata": {},
   "source": [
    "### OAS schema to GPT-compatible schema\n",
    "\n",
    "GPT currently recognizes only a limited number of descriptors when defining toolbox schema. Some of these descriptors (fields) can be directly transferred from OAS schema to toolbox, but many existing OAS schema fields will not be recognized by GPT and can cause errors. Therefore, transformation from OAS schemas to GPT-compatible schemas is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff74bc7e",
   "metadata": {},
   "source": [
    "GPT currently recognizes these fields:\n",
    "\n",
    "1. `type`  \n",
    "Specifies the data type of the value. Common types include:  \n",
    "  - `string` – A text string.  \n",
    "  - `number` – A numeric value (can be integer or floating point).  \n",
    "  - `integer` – A whole number.  \n",
    "  - `boolean` – A true/false value.  \n",
    "  - `array` – A list of items (you can define the type of items in the array as well).  \n",
    "  - `object` – A JSON object (with properties, which can be further defined with their own types).  \n",
    "  - `null` – A special type to represent a null or absent value.  \n",
    "  - `any` – Allows any type, typically used for flexible inputs or outputs.  \n",
    "2. `default`: Provides a default value for the field if the user doesn't supply one. It can be any valid type based on the expected schema.  \n",
    "3. `enum`: Specifies a list of acceptable values for a field. It restricts the input to one of the predefined values in the array.  \n",
    "4. `properties`: Used for objects, this defines the subfields of an object and their respective types.  \n",
    "5. `items`: Defines the type of items in an array. For example, you can specify that an array contains only strings or integers.  \n",
    "6. `minLength`, `maxLength`: Specifies minimum and maximum lengths for `string` parameters.  \n",
    "7. `minItems`, `maxItems`: Specifies mininum and maximum number of items for `array` parameters.  \n",
    "8. `pattern`: Specifies a regular expression that the string must match for `string` parameters.  \n",
    "9. `required`: A list of required fields for an `object`. Specifies that certain fields within an `object` must be provided.  \n",
    "10. `additionalProperties`: Specifies whether additional properties are allowed in an `object`. If set to `false`, no properties outside of those defined in properties will be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f62ab0",
   "metadata": {},
   "source": [
    "As such, we can extract corresponding fields from OAS schema, and converts all additional fields into parameter description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Directly transferable properties from OAS to GPT-compatible schema\n",
    "TRANSFERABLE_TYPES = [\n",
    "    \"type\", \"description\", \"default\", \"enum\", \"pattern\", \"additionalProperties\",\n",
    "    \"minLength\", \"maxLength\", \"minItems\", \"maxItems\"\n",
    "]\n",
    "\n",
    "# Function to transform OAS schema to GPT-compatible schema\n",
    "def transform_property(\n",
    "        prop: dict,  # The property to transform\n",
    "        flatten_refs: dict = {}  # The flattened references\n",
    "    ) -> tuple[dict, bool]:  # The transformed property and whether it is a required property\n",
    "\n",
    "    # If the property is a schema, flatten it\n",
    "    if \"schema\" in prop:\n",
    "        prop = copy.deepcopy(prop)\n",
    "        prop.update(prop[\"schema\"])\n",
    "        prop.pop(\"schema\")\n",
    "\n",
    "    # Extract the required field\n",
    "    required = prop.get(\"required\", False)\n",
    "    \n",
    "    # If the property is a reference, return it as is\n",
    "    if \"$ref\" in prop:\n",
    "        if prop[\"$ref\"] in flatten_refs:\n",
    "            ref_prop, _ = transform_property(flatten_refs[prop[\"$ref\"]], flatten_refs)\n",
    "            return ref_prop, required\n",
    "        else:\n",
    "            # If the reference is not found, return the reference as is\n",
    "            return prop, required \n",
    "    \n",
    "    # If the property is an object, transform it\n",
    "    new_prop = {}\n",
    "    additionals = {}\n",
    "\n",
    "    # If required is a list, it is directly transferable to GPT-compatible schema\n",
    "    if isinstance(required, list): \n",
    "        new_prop[\"required\"] = required\n",
    "        required = True\n",
    "\n",
    "    for key, value in prop.items():\n",
    "        if key in TRANSFERABLE_TYPES:\n",
    "            new_prop[key] = value\n",
    "        elif key == \"items\":\n",
    "            # Handle array items recursively\n",
    "            item_prop, _ = transform_property(value, flatten_refs)\n",
    "            new_prop[key] = item_prop\n",
    "        elif key == \"properties\":\n",
    "            # Handle nested properties recursively\n",
    "            new_prop[key] = {}\n",
    "            new_prop[\"required\"] = [] if \"required\" not in new_prop else new_prop[\"required\"]\n",
    "            for sub_key, sub_value in value.items():\n",
    "                sub_prop, sub_required = transform_property(sub_value, flatten_refs)\n",
    "                new_prop[key][sub_key] = sub_prop\n",
    "                if sub_required:\n",
    "                    new_prop[\"required\"].append(sub_key)\n",
    "        elif key == \"required\":\n",
    "            # Skip required field since it is handled in the properties section\n",
    "            continue\n",
    "        else:\n",
    "            # Collect unrecognized fields in additionals dictionary\n",
    "            additionals[key] = value\n",
    "\n",
    "    # Add the additionals dictionary if it is not empty\n",
    "    if len(additionals) > 0:\n",
    "        additional_info = \"; \".join([f\"{k.capitalize()}: {v}\" for k, v in additionals.items()])\n",
    "        if \"description\" in new_prop:\n",
    "            new_prop[\"description\"] += f\" ({additional_info})\"\n",
    "        else:\n",
    "            new_prop[\"description\"] = f\"({additional_info})\"\n",
    "\n",
    "    # Remove None values and return the transformed property\n",
    "    return {k: v for k, v in new_prop.items() if v is not None}, required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618d4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/oas_to_requests.py#L221){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### transform_property\n",
       "\n",
       ">      transform_property (prop:dict, flatten_refs:dict={})\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| prop | dict |  | The property to transform |\n",
       "| flatten_refs | dict | {} | The flattened references |\n",
       "| **Returns** | **tuple** |  | **The transformed property and whether it is a required property** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/oas_to_requests.py#L221){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### transform_property\n",
       "\n",
       ">      transform_property (prop:dict, flatten_refs:dict={})\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| prop | dict |  | The property to transform |\n",
       "| flatten_refs | dict | {} | The flattened references |\n",
       "| **Returns** | **tuple** |  | **The transformed property and whether it is a required property** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(transform_property)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418ecd9a",
   "metadata": {},
   "source": [
    "Test usage with complex parameters from DigiTraffic endpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6f546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"If parameter is given result will only contain update status. (Name: lastUpdated; In: query)\",\n",
      "  \"type\": \"boolean\",\n",
      "  \"default\": false\n",
      "}\n",
      "Required: False\n",
      "\n",
      "{\n",
      "  \"description\": \"Road number (Name: roadNumber; In: query; Format: int32)\",\n",
      "  \"type\": \"integer\"\n",
      "}\n",
      "Required: False\n",
      "\n",
      "{\n",
      "  \"description\": \"Minimum x coordinate (longitude) Coordinates are in WGS84 format in decimal degrees. Values between 19.0 and 32.0. (Name: xMin; In: query; Maximum: 32; Exclusivemaximum: False; Minimum: 19; Exclusiveminimum: False; Format: double)\",\n",
      "  \"type\": \"number\",\n",
      "  \"default\": 19\n",
      "}\n",
      "Required: False\n",
      "\n",
      "{\n",
      "  \"description\": \"Minimum y coordinate (latitude). Coordinates are in WGS84 format in decimal degrees. Values between 59.0 and 72.0. (Name: yMin; In: query; Maximum: 72; Exclusivemaximum: False; Minimum: 59; Exclusiveminimum: False; Format: double)\",\n",
      "  \"type\": \"number\",\n",
      "  \"default\": 59\n",
      "}\n",
      "Required: False\n",
      "\n",
      "{\n",
      "  \"description\": \"Maximum x coordinate (longitude). Coordinates are in WGS84 format in decimal degrees. Values between 19.0 and 32.0. (Name: xMax; In: query; Maximum: 32; Exclusivemaximum: False; Minimum: 19; Exclusiveminimum: False; Format: double)\",\n",
      "  \"type\": \"number\",\n",
      "  \"default\": 32\n",
      "}\n",
      "Required: False\n",
      "\n",
      "{\n",
      "  \"description\": \"Maximum y coordinate (latitude). Coordinates are in WGS84 format in decimal degrees. Values between 59.0 and 72.0. (Name: yMax; In: query; Maximum: 72; Exclusivemaximum: False; Minimum: 59; Exclusiveminimum: False; Format: double)\",\n",
      "  \"type\": \"number\",\n",
      "  \"default\": 72\n",
      "}\n",
      "Required: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = [\n",
    "    {\n",
    "        \"name\": \"lastUpdated\",\n",
    "        \"in\": \"query\",\n",
    "        \"description\": \"If parameter is given result will only contain update status.\",\n",
    "        \"required\": False,\n",
    "            \"schema\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"default\": False\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"roadNumber\",\n",
    "        \"in\": \"query\",\n",
    "        \"description\": \"Road number\",\n",
    "        \"required\": False,\n",
    "        \"schema\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int32\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"xMin\",\n",
    "        \"in\": \"query\",\n",
    "        \"description\": \"Minimum x coordinate (longitude) Coordinates are in WGS84 format in decimal degrees. Values between 19.0 and 32.0.\",\n",
    "        \"required\": False,\n",
    "        \"schema\": {\n",
    "            \"maximum\": 32,\n",
    "            \"exclusiveMaximum\": False,\n",
    "            \"minimum\": 19,\n",
    "            \"exclusiveMinimum\": False,\n",
    "            \"type\": \"number\",\n",
    "            \"format\": \"double\",\n",
    "            \"default\": 19\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"yMin\",\n",
    "        \"in\": \"query\",\n",
    "        \"description\": \"Minimum y coordinate (latitude). Coordinates are in WGS84 format in decimal degrees. Values between 59.0 and 72.0.\",\n",
    "        \"required\": False,\n",
    "        \"schema\": {\n",
    "            \"maximum\": 72,\n",
    "            \"exclusiveMaximum\": False,\n",
    "            \"minimum\": 59,\n",
    "            \"exclusiveMinimum\": False,\n",
    "            \"type\": \"number\",\n",
    "            \"format\": \"double\",\n",
    "            \"default\": 59\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"xMax\",\n",
    "        \"in\": \"query\",\n",
    "        \"description\": \"Maximum x coordinate (longitude). Coordinates are in WGS84 format in decimal degrees. Values between 19.0 and 32.0.\",\n",
    "        \"required\": False,\n",
    "        \"schema\": {\n",
    "            \"maximum\": 32,\n",
    "            \"exclusiveMaximum\": False,\n",
    "            \"minimum\": 19,\n",
    "            \"exclusiveMinimum\": False,\n",
    "            \"type\": \"number\",\n",
    "            \"format\": \"double\",\n",
    "            \"default\": 32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"yMax\",\n",
    "        \"in\": \"query\",\n",
    "        \"description\": \"Maximum y coordinate (latitude). Coordinates are in WGS84 format in decimal degrees. Values between 59.0 and 72.0.\",\n",
    "        \"required\": False,\n",
    "        \"schema\": {\n",
    "            \"maximum\": 72,\n",
    "            \"exclusiveMaximum\": False,\n",
    "            \"minimum\": 59,\n",
    "            \"exclusiveMinimum\": False,\n",
    "            \"type\": \"number\",\n",
    "            \"format\": \"double\",\n",
    "            \"default\": 72\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "for param in parameters:\n",
    "    param, required = transform_property(param)\n",
    "    print(json.dumps(param, indent=2))\n",
    "    print(f\"Required: {required}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71473afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Sample OAS schema with nested schema properties\n",
    "\n",
    "flatten_refs = {\n",
    "    \"#/components/schemas/dimensions\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"width\": {\n",
    "                \"type\": \"number\",\n",
    "                \"minimum\": 0,\n",
    "                \"description\": \"Width in centimeters.\",\n",
    "                \"required\": True\n",
    "            },\n",
    "            \"height\": {\n",
    "                \"type\": \"number\",\n",
    "                \"minimum\": 0,\n",
    "                \"description\": \"Height in centimeters.\",\n",
    "                \"required\": True\n",
    "            },\n",
    "            \"depth\": {\n",
    "                \"type\": \"number\",\n",
    "                \"minimum\": 0,\n",
    "                \"description\": \"Depth in centimeters.\",\n",
    "                \"required\": True\n",
    "            }\n",
    "        },\n",
    "        \"description\": \"Dimensions of the product.\"\n",
    "    }\n",
    "}\n",
    "        \n",
    "nested_param = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"product\": {\n",
    "            \"type\": \"object\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Unique identifier for the product.\"\n",
    "                    },\n",
    "                    \"details\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"schema\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"weight\": {\n",
    "                                    \"type\": \"number\",\n",
    "                                    \"minimum\": 0,\n",
    "                                    \"description\": \"Weight of the product in kilograms.\"\n",
    "                                },\n",
    "                                \"dimensions\": {\n",
    "                                    \"schema\":\n",
    "                                        {\n",
    "                                        \"$ref\": \"#/components/schemas/dimensions\"\n",
    "                                        }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"description\": \"Detailed specifications of the product.\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"description\": \"Product information.\"\n",
    "        },\n",
    "        \"category\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Category of the product.\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"product\", \"category\"]\n",
    "}\n",
    "\n",
    "transformed_param, _ = transform_property(nested_param, flatten_refs)\n",
    "assert transformed_param == {\n",
    "  \"required\": [\n",
    "    \"product\",\n",
    "    \"category\"\n",
    "  ],\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"product\": {\n",
    "      \"type\": \"object\",\n",
    "      \"description\": \"Product information.\",\n",
    "      \"properties\": {\n",
    "        \"id\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Unique identifier for the product.\"\n",
    "        },\n",
    "        \"details\": {\n",
    "          \"type\": \"object\",\n",
    "          \"description\": \"Detailed specifications of the product.\",\n",
    "          \"properties\": {\n",
    "            \"weight\": {\n",
    "              \"type\": \"number\",\n",
    "              \"description\": \"Weight of the product in kilograms. (Minimum: 0)\"\n",
    "            },\n",
    "            \"dimensions\": {\n",
    "              \"type\": \"object\",\n",
    "              \"description\": \"Dimensions of the product.\",\n",
    "              \"properties\": {\n",
    "                \"width\": {\n",
    "                  \"type\": \"number\",\n",
    "                  \"description\": \"Width in centimeters. (Minimum: 0)\"\n",
    "                },\n",
    "                \"height\": {\n",
    "                  \"type\": \"number\",\n",
    "                  \"description\": \"Height in centimeters. (Minimum: 0)\"\n",
    "                },\n",
    "                \"depth\": {\n",
    "                  \"type\": \"number\",\n",
    "                  \"description\": \"Depth in centimeters. (Minimum: 0)\"\n",
    "                }\n",
    "              },\n",
    "              \"required\": [\n",
    "                \"width\",\n",
    "                \"height\",\n",
    "                \"depth\"\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "          \"required\": []\n",
    "        }\n",
    "      },\n",
    "      \"required\": []\n",
    "    },\n",
    "    \"category\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"Category of the product.\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2e53ee",
   "metadata": {},
   "source": [
    "## Executing requests with GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc49e43b",
   "metadata": {},
   "source": [
    "### Auxiliary function to generate requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_request(\n",
    "    function_name: str,  # The name of the function\n",
    "    url: str,  # The URL of the request\n",
    "    method: str,  # The method of the request\n",
    "    path: dict = {},  # The path parameters of the request\n",
    "    query: dict = {},  # The query parameters of the request\n",
    "    body: dict = {},  # The body of the request\n",
    "    accepted_queries: list = [],  # The accepted queries of the request\n",
    "    **kwargs  # Additional parameters\n",
    ") -> dict:  # The response of the request\n",
    "    \"\"\"Generate a request from the function name and parameters.\"\"\"\n",
    "    # Extract the URL and method from the toolbox if not provided\n",
    "    if url is None or method is None:\n",
    "        raise ValueError(\"URL and method must be provided.\")\n",
    "    \n",
    "    # Prepare the request\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Extract the accepted queries\n",
    "    queries = {k: v for k, v in query.items() if k in accepted_queries}\n",
    "    queries.update({k: v for k, v in kwargs.items() if k in accepted_queries})\n",
    "\n",
    "    # Execute the request\n",
    "    response = requests.request(\n",
    "        method,\n",
    "        url.format(**path, **kwargs),\n",
    "        headers=headers,\n",
    "        params=queries if len(queries) > 0 else None,\n",
    "        json=body if len(body) > 0 else None\n",
    "    )\n",
    "\n",
    "    # Return the response (either as JSON or text)\n",
    "    try:\n",
    "        return response.json()\n",
    "    except:\n",
    "        return {\"message\": response.text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50e70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/oas_to_requests.py#L289){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### generate_request\n",
       "\n",
       ">      generate_request (function_name:str, url:str, method:str, path:dict={},\n",
       ">                        query:dict={}, body:dict={}, accepted_queries:list=[],\n",
       ">                        **kwargs)\n",
       "\n",
       "*Generate a request from the function name and parameters.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| function_name | str |  | The name of the function |\n",
       "| url | str |  | The URL of the request |\n",
       "| method | str |  | The method of the request |\n",
       "| path | dict | {} | The path parameters of the request |\n",
       "| query | dict | {} | The query parameters of the request |\n",
       "| body | dict | {} | The body of the request |\n",
       "| accepted_queries | list | [] | The accepted queries of the request |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **dict** |  | **The response of the request** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/oas_to_requests.py#L289){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### generate_request\n",
       "\n",
       ">      generate_request (function_name:str, url:str, method:str, path:dict={},\n",
       ">                        query:dict={}, body:dict={}, accepted_queries:list=[],\n",
       ">                        **kwargs)\n",
       "\n",
       "*Generate a request from the function name and parameters.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| function_name | str |  | The name of the function |\n",
       "| url | str |  | The URL of the request |\n",
       "| method | str |  | The method of the request |\n",
       "| path | dict | {} | The path parameters of the request |\n",
       "| query | dict | {} | The query parameters of the request |\n",
       "| body | dict | {} | The body of the request |\n",
       "| accepted_queries | list | [] | The accepted queries of the request |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **dict** |  | **The response of the request** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(generate_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8caabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'id': 'C01504',\n",
       " 'geometry': {'type': 'Point', 'coordinates': [24.235601, 60.536727, 0.0]},\n",
       " 'properties': {'id': 'C01504',\n",
       "  'name': 'vt2_Karkkila_Korpi',\n",
       "  'cameraType': 'HIKVISION',\n",
       "  'nearestWeatherStationId': 1052,\n",
       "  'collectionStatus': 'GATHERING',\n",
       "  'state': None,\n",
       "  'dataUpdatedTime': '2024-12-09T15:27:13Z',\n",
       "  'collectionInterval': 600,\n",
       "  'names': {'fi': 'Tie 2 Karkkila, Kappeli',\n",
       "   'sv': 'Väg 2 Högfors, Kappeli',\n",
       "   'en': 'Road 2 Karkkila, Kappeli'},\n",
       "  'roadAddress': {'roadNumber': 2,\n",
       "   'roadSection': 13,\n",
       "   'distanceFromRoadSectionStart': 3818,\n",
       "   'carriageway': 'ONE_CARRIAGEWAY',\n",
       "   'side': 'LEFT',\n",
       "   'contractArea': '',\n",
       "   'contractAreaCode': 344},\n",
       "  'liviId': 'Livi1089298',\n",
       "  'country': None,\n",
       "  'startTime': '1995-06-01T00:00:00Z',\n",
       "  'repairMaintenanceTime': None,\n",
       "  'annualMaintenanceTime': None,\n",
       "  'purpose': 'keli',\n",
       "  'municipality': 'Karkkila',\n",
       "  'municipalityCode': 224,\n",
       "  'province': 'Uusimaa',\n",
       "  'provinceCode': 1,\n",
       "  'presets': [{'id': 'C0150401',\n",
       "    'presentationName': 'Poriin',\n",
       "    'inCollection': True,\n",
       "    'resolution': 'videoResolutionWidth=1280&videoResolutionHeight=720',\n",
       "    'directionCode': '1',\n",
       "    'imageUrl': 'https://weathercam.digitraffic.fi/C0150401.jpg',\n",
       "    'direction': 'INCREASING_DIRECTION'},\n",
       "   {'id': 'C0150402',\n",
       "    'presentationName': 'Helsinkiin',\n",
       "    'inCollection': True,\n",
       "    'resolution': 'videoResolutionWidth=1280&videoResolutionHeight=720',\n",
       "    'directionCode': '2',\n",
       "    'imageUrl': 'https://weathercam.digitraffic.fi/C0150402.jpg',\n",
       "    'direction': 'DECREASING_DIRECTION'},\n",
       "   {'id': 'C0150409',\n",
       "    'presentationName': 'Tienpinta',\n",
       "    'inCollection': True,\n",
       "    'resolution': 'videoResolutionWidth=1280&videoResolutionHeight=720',\n",
       "    'directionCode': '9',\n",
       "    'imageUrl': 'https://weathercam.digitraffic.fi/C0150409.jpg',\n",
       "    'direction': 'SPECIAL_DIRECTION'}]}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_request(\n",
    "    function_name=\"weathercamStations\",\n",
    "    url=\"https://tie.digitraffic.fi/api/weathercam/v1/stations/{id}\",\n",
    "    method=\"GET\",\n",
    "    path={\"id\": \"C01504\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c309cc",
   "metadata": {},
   "source": [
    "### API schema\n",
    "\n",
    "Extract important information about the functions and creates a GPT-compatible toolbox schema. The idea is to convert all necessary information for generating an API request to a parameter for GPT to provide. As such, the parameters of each function in this toolbox schema will include:\n",
    "\n",
    "- `url`: URL to send requests to (type `string`, with `const` default value formed with a base URL and endpoint path) \n",
    "- `method`: HTTP method for each endpoint (type `string`, with `const` value)\n",
    "- `path`: dictionary for path parameters that maps parameter names to schema\n",
    "- `query`: dictionary for query parameters that maps parameter names to schema\n",
    "- `body`: request body schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1b624",
   "metadata": {},
   "source": [
    "Test with usage from DigiTraffic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41993212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def api_schema(\n",
    "        base_url: str,  # The base URL of the API\n",
    "        oas: dict,  # The OpenAPI schema\n",
    "        service_name: Optional[str]=None,  # The name of the service\n",
    "        fixup:Callable=None, # a fixup function to execute a REST API when a function name isn't found.\n",
    "    ) -> dict:  # The api schema\n",
    "    \"\"\"Form the toolbox schema from the OpenAPI schema.\"\"\"\n",
    "    \n",
    "    # Extract the references\n",
    "    flatten_refs = extract_refs(oas)\n",
    "    \n",
    "    # Initialize the toolbox\n",
    "    toolbox = []\n",
    "\n",
    "    # Traverse the paths section of the spec\n",
    "    for path, methods in oas[\"paths\"].items():\n",
    "        for method, info in methods.items():\n",
    "            # Extract the function name\n",
    "            name = info[\"operationId\"] if \"operationId\" in info else \\\n",
    "                f\"{method}{path.replace('/', '_').replace('{', 'by').replace('}', '').replace('-', '_')}\"\n",
    "            name = re.sub(r'[^a-zA-Z0-9_-]', '_', name)\n",
    "\n",
    "            # Extract the function description\n",
    "            description = info[\"description\"] if \"description\" in info else info.get(\"summary\", \"\")\n",
    "\n",
    "            # Extract the function parameters\n",
    "            parameters = {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},   \n",
    "                \"required\": []\n",
    "            }\n",
    "            accepted_queries = []\n",
    "\n",
    "            # Extract endpoint parameters\n",
    "            if \"parameters\" in info:\n",
    "                for param in info[\"parameters\"]:\n",
    "                    # Extract the parameter location (query, path, header, cookie)\n",
    "                    location = param.get(\"in\", \"query\")\n",
    "\n",
    "                    # Initialize the parameter object based on location\n",
    "                    if location not in parameters[\"properties\"]:\n",
    "                        parameters[\"properties\"][location] = {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {},\n",
    "                            \"required\": []\n",
    "                        }\n",
    "\n",
    "                    # Extract the parameter schema\n",
    "                    param_obj, required = transform_property(param, flatten_refs)\n",
    "\n",
    "                    # Add the parameter to the toolbox\n",
    "                    parameters[\"properties\"][location][\"properties\"][param[\"name\"]] = param_obj\n",
    "                    if required or location == \"path\":\n",
    "                        parameters[\"properties\"][location][\"required\"].append(param[\"name\"])\n",
    "                        parameters[\"required\"].append(location)\n",
    "\n",
    "                    # Add the parameter to the accepted queries\n",
    "                    if location == \"query\":\n",
    "                        accepted_queries.append(param[\"name\"])\n",
    "                    \n",
    "            # Extract the function body\n",
    "            body = {}\n",
    "            if \"requestBody\" in info and \"content\" in info[\"requestBody\"] \\\n",
    "                    and \"application/json\" in info[\"requestBody\"][\"content\"] \\\n",
    "                    and \"schema\" in info[\"requestBody\"][\"content\"][\"application/json\"]:\n",
    "                body = info[\"requestBody\"][\"content\"][\"application/json\"]\n",
    "                body, _ = transform_property(body, flatten_refs)\n",
    "                parameters[\"properties\"][\"body\"] = body\n",
    "                parameters[\"required\"].append(\"body\")\n",
    "\n",
    "            # Remove duplicate required properties\n",
    "            parameters[\"required\"] = list(set(parameters[\"required\"]))\n",
    "                \n",
    "            # Conclude the function information\n",
    "            function = {\n",
    "                \"name\": name,\n",
    "                \"description\": description,\n",
    "                \"parameters\": parameters,\n",
    "                \"metadata\": {\n",
    "                    \"url\": base_url + path,\n",
    "                    \"method\": method,\n",
    "                    \"accepted_queries\": accepted_queries,\n",
    "                }\n",
    "            }\n",
    "            if fixup: function['fixup'] = f\"{fixup.__module__}.{fixup.__name__}\"\n",
    "            if service_name: function[\"metadata\"][\"service\"] = service_name\n",
    "\n",
    "            # Add the function to the toolbox\n",
    "            toolbox.append(\n",
    "                {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": function\n",
    "                }\n",
    "            )\n",
    "        \n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1dc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/oas_to_requests.py#L329){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### api_schema\n",
       "\n",
       ">      api_schema (base_url:str, oas:dict, service_name:Optional[str]=None,\n",
       ">                  fixup:Callable=None)\n",
       "\n",
       "*Form the toolbox schema from the OpenAPI schema.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| base_url | str |  | The base URL of the API |\n",
       "| oas | dict |  | The OpenAPI schema |\n",
       "| service_name | Optional | None | The name of the service |\n",
       "| fixup | Callable | None | a fixup function to execute a REST API when a function name isn't found. |\n",
       "| **Returns** | **dict** |  | **The api schema** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ninjalabo/llmcam/blob/main/llmcam/oas_to_requests.py#L329){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### api_schema\n",
       "\n",
       ">      api_schema (base_url:str, oas:dict, service_name:Optional[str]=None,\n",
       ">                  fixup:Callable=None)\n",
       "\n",
       "*Form the toolbox schema from the OpenAPI schema.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| base_url | str |  | The base URL of the API |\n",
       "| oas | dict |  | The OpenAPI schema |\n",
       "| service_name | Optional | None | The name of the service |\n",
       "| fixup | Callable | None | a fixup function to execute a REST API when a function name isn't found. |\n",
       "| **Returns** | **dict** |  | **The api schema** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(api_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52e555-e2ae-4e63-bb3a-609d1f32deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_schema = api_schema(base_url=BASE_URL, oas=oas, fixup=generate_request)\n",
    "#pprint(tool_schema[:3])\n",
    "for ts in tool_schema:\n",
    "    if ts['function']['name']=='getLatestTrafficRestrictionNotificationById':\n",
    "        print(json.dumps(ts['function'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490c344",
   "metadata": {},
   "source": [
    "### GPT integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f872c7",
   "metadata": {},
   "source": [
    "Integrate with existing `complete` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf1414-e0e1-4538-8fc8-8e4b035e3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from llmcam.core.fn_to_fc import complete, form_msgs, print_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda34fa-0ca6-4e89-a248-4e7e24518f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[31mSystem:\u001b[0m\n",
      "You are a helpful system administrator. Use the supplied tools to help the user.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "Get the weather camera information for the stations with ID C01503 and C01504.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "Here is the weather camera information for the stations with IDs C01503 and C01504:  ### Station\n",
      "C01503 (Road 51 Inkoo) - **Camera Type:** BOSCH - **Nearest Weather Station ID:** 1013 -\n",
      "**Collection Status:** GATHERING - **Data Updated Time:** 2024-12-09T15:25:44Z - **Collection\n",
      "Interval:** 600 seconds - **Municipality:** Inkoo - **Municipality Code:** 149 - **Province:**\n",
      "Uusimaa - **Province Code:** 1  **Coordinates:** [Longitude: 23.99616, Latitude: 60.05374]\n",
      "**Presets:** 1. **Inkooseen:**     - [Image](https://weathercam.digitraffic.fi/C0150301.jpg)    -\n",
      "Direction: INCREASING_DIRECTION    - Resolution: 1280x720  2. **Hankoon:**     -\n",
      "[Image](https://weathercam.digitraffic.fi/C0150302.jpg)    - Direction: DECREASING_DIRECTION    -\n",
      "Resolution: 1280x720  3. **Tienpinta:**     -\n",
      "[Image](https://weathercam.digitraffic.fi/C0150309.jpg)    - Direction: SPECIAL_DIRECTION    -\n",
      "Resolution: 1280x720  ---  ### Station C01504 (Road 2 Karkkila, Kappeli) - **Camera Type:**\n",
      "HIKVISION - **Nearest Weather Station ID:** 1052 - **Collection Status:** GATHERING - **Data Updated\n",
      "Time:** 2024-12-09T15:27:13Z - **Collection Interval:** 600 seconds - **Municipality:** Karkkila -\n",
      "**Municipality Code:** 224 - **Province:** Uusimaa - **Province Code:** 1  **Coordinates:**\n",
      "[Longitude: 24.235601, Latitude: 60.536727]  **Presets:** 1. **Poriin:**     -\n",
      "[Image](https://weathercam.digitraffic.fi/C0150401.jpg)    - Direction: INCREASING_DIRECTION    -\n",
      "Resolution: 1280x720  2. **Helsinkiin:**     -\n",
      "[Image](https://weathercam.digitraffic.fi/C0150402.jpg)    - Direction: DECREASING_DIRECTION    -\n",
      "Resolution: 1280x720  3. **Tienpinta:**     -\n",
      "[Image](https://weathercam.digitraffic.fi/C0150409.jpg)    - Direction: SPECIAL_DIRECTION    -\n",
      "Resolution: 1280x720  Feel free to let me know if you need more information!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "messages = form_msgs([\n",
    "    (\"system\", \"You are a helpful system administrator. Use the supplied tools to help the user.\"),\n",
    "    (\"user\", \"Get the weather camera information for the stations with ID C01503 and C01504.\"),\n",
    "])\n",
    "complete(messages, tool_schema)\n",
    "print_msgs(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809f4d1-b0c1-4528-bcf8-682ca49b26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
