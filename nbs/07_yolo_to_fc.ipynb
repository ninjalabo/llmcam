{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import openai\n",
    "from llmcam.fn_to_fc import complete, tool_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image_path: str, conf: float=0.05):\n",
    "    \"\"\"Run YOLO object detection on an input image.\"\"\"\n",
    "    model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
    "    model.conf = conf  # NMS confidence threshold\n",
    "    \n",
    "    results = model(image_path)\n",
    "    count = results.pandas().xyxy[0]['name'].value_counts().to_dict()\n",
    "    return json.dumps(count, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\":\"system\", \n",
    "        \"content\":\"You are a helpful system administrator. Use the supplied tools to assist the user. Only use one tool at a time.\\\n",
    "        If you cannot decide which tool to use, ask the user for more information.\"    \n",
    "    },\n",
    "]\n",
    "# tools = [tool_schema(detect_objects)]\n",
    "# def fn_name(res): return res.tool_calls[0].function.name\n",
    "# def fn_args(res): return json.loads(res.tool_calls[0].function.arguments)    \n",
    "# def fn_exec(res): return globals().get(fn_name(res))(**fn_args(res)) # This one cannot be imported for use from other notebooks, hence the copy\n",
    "# def fn_result_content(res):\n",
    "#     \"\"\"Create a content containing the result of the function call\"\"\"\n",
    "#     content = dict()\n",
    "#     content.update(fn_args(res))\n",
    "#     content.update({fn_name(res): fn_exec(res)})\n",
    "#     return json.dumps(content)\n",
    "# # generate_messages will use the tools defined in 06_fn_to_fc.ipynb\n",
    "# def complete(\n",
    "#     role: str,  # The role of the message sender; Literal is not supported on my computer\n",
    "#     content: str,  # The content of the message\n",
    "#     tool_call_id=None):\n",
    "#     \"\"\"Send completion request with messages, and save the response in messages again\"\"\"\n",
    "#     messages.append({\"role\":role, \"content\":content, \"tool_call_id\":tool_call_id})\n",
    "#     response = openai.chat.completions.create(\n",
    "#         model=\"gpt-4o\", \n",
    "#         messages=messages, \n",
    "#         tools=tools\n",
    "#     )\n",
    "#     res = response.choices[0].message\n",
    "#     messages.append(res.to_dict())\n",
    "#     if res.to_dict().get('tool_calls'):\n",
    "#         complete(role=\"tool\", content=fn_result_content(res), tool_call_id=res.tool_calls[0].id)\n",
    "#     return messages[-1]['role'], messages[-1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     },\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      8\u001b[0m tools \u001b[38;5;241m=\u001b[39m [tool_schema(detect_objects)]\n\u001b[0;32m----> 9\u001b[0m \u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCan you detect the objects in this image\u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m          https://homebodyeats.com/wp-content/uploads/2021/11/thanksgiving-cheese-board.jpg? with threshold 0.1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/llmcam/llmcam/fn_to_fc.py:182\u001b[0m, in \u001b[0;36mcomplete\u001b[0;34m(messages, role, content, tools, tool_call_id, aux_fn)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Handle the tool response\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mto_dict()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtool_calls\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    179\u001b[0m     complete(\n\u001b[1;32m    180\u001b[0m         messages, \n\u001b[1;32m    181\u001b[0m         role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m--> 182\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[43mfn_result_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[1;32m    183\u001b[0m         tools\u001b[38;5;241m=\u001b[39mtools, \n\u001b[1;32m    184\u001b[0m         tool_call_id\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mtool_calls[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mid, \n\u001b[1;32m    185\u001b[0m         aux_fn\u001b[38;5;241m=\u001b[39maux_fn\n\u001b[1;32m    186\u001b[0m     )\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Return the last message\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m], messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/llmcam/llmcam/fn_to_fc.py:156\u001b[0m, in \u001b[0;36mfn_result_content\u001b[0;34m(res, aux_fn, tools)\u001b[0m\n\u001b[1;32m    154\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    155\u001b[0m content\u001b[38;5;241m.\u001b[39mupdate(fn_args(res))\n\u001b[0;32m--> 156\u001b[0m content\u001b[38;5;241m.\u001b[39mupdate({fn_name(res): \u001b[43mfn_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m})\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps(content)\n",
      "File \u001b[0;32m~/llmcam/llmcam/fn_to_fc.py:150\u001b[0m, in \u001b[0;36mfn_exec\u001b[0;34m(res, aux_fn, tools)\u001b[0m\n\u001b[1;32m    148\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mget(fn_name(res))\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn: \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args(res))\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maux_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\":\"system\", \n",
    "        \"content\":\"You are a helpful system administrator. Use the supplied tools to assist the user. Only use one tool at a time.\\\n",
    "        If you cannot decide which tool to use, ask the user for more information.\"    \n",
    "    },\n",
    "]\n",
    "tools = [tool_schema(detect_objects)]\n",
    "complete(messages, 'user', 'Can you detect the objects in this image\\\n",
    "          https://homebodyeats.com/wp-content/uploads/2021/11/thanksgiving-cheese-board.jpg? with threshold 0.1', tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/abc/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-11-10 Python-3.10.15 torch-2.5.1+cu124 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "/home/abc/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful system administrator. Use the supplied tools to assist the user. Only use one tool at a time.        If you cannot decide which tool to use, ask the user for more information.\n",
      "User: Can you detect the objects in this image https://homebodyeats.com/wp-content/uploads/2021/11/thanksgiving-cheese-board.jpg? with threshold 0.1\n",
      "Assistant: None\n",
      "Tool: {\"image_path\": \"https://homebodyeats.com/wp-content/uploads/2021/11/thanksgiving-cheese-board.jpg\", \"conf\": 0.1, \"detect_objects\": \"{\\n  \\\"bowl\\\": 5,\\n  \\\"cup\\\": 2,\\n  \\\"sandwich\\\": 1,\\n  \\\"dining table\\\": 1,\\n  \\\"knife\\\": 1,\\n  \\\"cake\\\": 1\\n}\"}\n",
      "Assistant: The objects detected in the image with a confidence threshold of 0.1 are as follows:\n",
      "\n",
      "- Bowl: 5\n",
      "- Cup: 2\n",
      "- Sandwich: 1\n",
      "- Dining table: 1\n",
      "- Knife: 1\n",
      "- Cake: 1\n",
      "\n",
      "If you need any further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "complete(\"user\", \"Can you detect the objects in this image https://homebodyeats.com/wp-content/uploads/2021/11/thanksgiving-cheese-board.jpg? with threshold 0.1\")\n",
    "for message in messages:\n",
    "    print(f\"{message['role'].capitalize()}: {message['content']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ninjalabo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
