{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea387527-2ef4-43bb-b6f1-616e5e313757",
   "metadata": {},
   "source": [
    "# Demo Scenario 1\n",
    "> Validate Demonstrate Scenario 1 on a notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9a2b6",
   "metadata": {},
   "source": [
    "The goal of this demo is to demonstrate the utilities to dynamically import new tools via GPT Function calling, as well as incorporating some of our built-in tools in a relevant use case. \n",
    "\n",
    "The scenario in this demo is a user wanting to retrieve information about traffic information. Without our application, the user needs to access an online service (e.g., Road DigiTraffic) about traffic information, navigate through the website UI, and making requests to the service with appropriate commands / UI navigation. However, the problem in this manual approach is that it can be time-consuming, prone to user error, and inefficient, especially if the user is unfamiliar with the website’s interface or the specific commands required. It is also difficult for the user to combine the information with other utilities.\n",
    "\n",
    "Our application can resolve these issues by dynamically importing API endpoints as tools for GPT FC. API endpoints are the backbone of an online service, so directly importing them as tools mean that GPT FC can operate all utilities available to the user. With this setup, GPT FC can interpret the user’s chat instructions, automatically operate the appropriate functions, and provide accurate, real-time traffic data efficiently. This simplifies the process of navigating through the utilities of a service and ensures that users can easily combine the information with other tools or workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2ac05-3b84-4189-a763-5bb72027e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a009fa6",
   "metadata": {},
   "source": [
    "## Step 1 - Preparation\n",
    "\n",
    "For this demo, to fully demonstrate the dynamic imports via GPT FC, we will import only functions from `llmcam.utils.store` as built-in GPT FC tools. This function will be responsible for dynamically importing any tools that we use subsequently.\n",
    "\n",
    "At this step, the main tasks are:\n",
    "\n",
    "- Import `llmcam.core` modules and `llmcam.utils.store` module.  \n",
    "- Set up initial `tools` list and its handler as instructed in `utils/01_store.ipynb` notebook.  \n",
    "- Verify set up with GPT messages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d0c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Import all the necessary modules\n",
    "from llmcam.core.fc import *\n",
    "from llmcam.core.fn_to_schema import *\n",
    "from llmcam.utils.store import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d35371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Set up `tools` list and `execute_handler` function\n",
    "tools = []\n",
    "def execute_handler(function_name, **kwargs):\n",
    "    execute_handler_core(tools, function_name, **kwargs)\n",
    "\n",
    "# Add default tools from `llmcam.utils.store` built-in functions\n",
    "tools.extend([handler_schema(function, service_name=\"toolbox_handler\", fixup=execute_handler) for function in [\n",
    "    add_api_tools,\n",
    "    add_function_tools,\n",
    "    remove_tools\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14744936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "I can add, remove, and manage tools related to API services and function tools within the\n",
      "`functions` namespace. I also have a capability to execute multiple tool operations in parallel\n",
      "using the `multi_tool_use.parallel` function. If you need a specific API or functionality, let me\n",
      "know, and I can manage the tools accordingly.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Start the conversation and verify the tools\n",
    "messages = form_msgs([\n",
    "    (\"system\", \"You are a helpful system administrator. Use the supplied tools to help the user.\"),\n",
    "    (\"user\", \"What tools can you use?\")\n",
    "])\n",
    "complete(messages, tools=tools)\n",
    "print_msg(messages[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd894276",
   "metadata": {},
   "source": [
    "The GPT agent should list all the 3 built-in tools from `llmcam.utils.store`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea7dac",
   "metadata": {},
   "source": [
    "## Step 2 - Integrate Road DigiTraffic\n",
    "\n",
    "At this step, we will integrate Road DigiTraffic via its base API service and OpenAPI Specification file. This service is public and users can retrieve traffic information by accessing its API endpoints with HTTPS requests. The official documentation is available at: https://www.digitraffic.fi/tieliikenne/. The base URL for making requests is https://tie.digitraffic.fi, while its OAS file is downloadable from the URL https://tie.digitraffic.fi/swagger/openapi.json.\n",
    "\n",
    "As such, this service provides all information we need for incorporating it to GPT FC via `llmcam.utils.store`. It is also without the use of tokens or security schemes that our service is currently not accounting for. In this demo, we can use it to retrieve information about weather cameras and thereby incorporate further with our vision modules.\n",
    "\n",
    "The main tasks for integrating Road DigiTraffic include:\n",
    "\n",
    "- Add Road DigiTraffic with necessary information.  \n",
    "- Check for available tools.  \n",
    "- Make a request about weather camera stations.  \n",
    "- (Optional) Prune tool call results as response from Road DigiTraffic can exceed maximum tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0788c030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "The new API service 'road_digitraffic' has been successfully added with the base URL\n",
      "'https://tie.digitraffic.fi' and the OpenAPI Specification URL\n",
      "'https://tie.digitraffic.fi/swagger/openapi.json'.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Add a new API service called 'road_digitraffic' with necessary details\n",
    "messages.append(form_msg(\n",
    "    \"user\", \n",
    "    \"Add a new API service called 'road_digitraffic'. \\\n",
    "Use the base URL 'https://tie.digitraffic.fi', \\\n",
    "and the OpenAPI Specification URL 'https://tie.digitraffic.fi/swagger/openapi.json'.\"\n",
    "))\n",
    "complete(messages, tools=tools)\n",
    "print_msg(messages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616791d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "I now have access to the following tools within the `functions` namespace:  1. **Road Digitraffic\n",
      "API Tools** (from the recently added 'road_digitraffic' service):    - Access various endpoints\n",
      "related to traffic measurement, weather stations, maintenance tracking, and more.  2. **Multi Tool\n",
      "Execution**:    - `multi_tool_use.parallel`: Execute multiple tools in parallel when they can\n",
      "operate independently.  If you need specific functionalities or data, feel free to ask, and I can\n",
      "use the appropriate tool.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Verify the added API service\n",
    "messages.append(form_msg(\"user\", \"What tools can you use?\"))\n",
    "complete(messages, tools=tools)\n",
    "print_msg(messages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a81a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "There is a traffic situation report for a traffic jam right now:  - **Location:** Road 6,\n",
      "Lappeenranta, Finland - **Nature of Incident:** Preliminary accident report - **Specific Location:**\n",
      "Between Laihian junction bridge and Muuko interchange - **Coordinates:** Path through multiple\n",
      "points from [28.315513, 61.073364] to [28.348438, 61.084576] - **Start Time:** December 19, 2024,\n",
      "23:08:00 UTC - **Expected End Time:** December 19, 2024, 23:38:14 UTC - **Additional Information:**\n",
      "[Traffic Information and Road Conditions Online](https://liikennetilanne.fintraffic.fi/) -\n",
      "**Contact:** Fintraffic Tieliikennekeskus Tampere, Phone: 02002100, Email:\n",
      "tampere.liikennekeskus@fintraffic.fi  If you need more detailed information about other locations or\n",
      "traffic situations, let me know!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Make a request to the 'road_digitraffic' API service to get the traffic information\n",
    "messages.append(form_msg(\"user\", \"Can you tell me where exists traffic jam right now?\"))\n",
    "complete(messages, tools=tools)\n",
    "print_msg(messages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6031794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "messages = [ message for message in messages if message[\"role\"] != \"tool\" and message[\"content\"] != None ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e817e9bc",
   "metadata": {},
   "source": [
    "## Step 3 - Integrate `llmcam.vision` modules\n",
    "\n",
    "We can combine the information about weather camera stations with our existing functions to capture images from weather cameras and detect objects in images. To demonstrate further the utilities from `llmcam.utils.store`, we can try dynamically importing this built-in functions with GPT FC.\n",
    "\n",
    "In this step, the main tasks include:\n",
    "\n",
    "- Add necessary tools with full module source and function names `llmcam.vision.dtcam.cap` and `llmcam.vision.yolo.detect_objects`.  \n",
    "- Make command to capture image from a specified weather camera and detect objects from it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "The new service 'vision' has been added with the functions `llmcam.vision.dtcam.cap` and\n",
      "`llmcam.vision.yolo.detect_objects`. If you need to utilize these functions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Add the functions `llmcam.vision.dtcam.cap` and `llmcam.vision.yolo.detect_objects` to the new service 'vision'\n",
    "messages.append(form_msg(\n",
    "    \"user\", \n",
    "    \"Add a new service called `vision` with the functions `llmcam.vision.dtcam.cap` and \\\n",
    "`llmcam.vision.yolo.detect_objects`.\"))\n",
    "complete(messages, tools=tools)\n",
    "print_msg(messages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b0f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nghivo/tinyMLaaS/llmcam/data/cap_2024.12.19_23:26:51_Imatralle_C0352901.jpg: 384x640 (no detections), 47.9ms\n",
      "Speed: 6.6ms preprocess, 47.9ms inference, 51.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "Here is an image captured from a weather camera in Lappeenranta:  ![Lappeenranta Weather\n",
      "Camera](sandbox:/home/nghivo/tinyMLaaS/llmcam/data/cap_2024.12.19_23:26:51_Imatralle_C0352901.jpg)\n",
      "Unfortunately, no objects were detected in this image. If you have any other requests or need\n",
      "additional information, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Use the functions to show an image with a weather camera and detect objects in it\n",
    "messages.append(form_msg(\n",
    "    \"user\", \n",
    "    \"Show me an image in Lappeenranta with a weather camera \\\n",
    "and detect objects in it.\"))\n",
    "complete(messages, tools=tools)\n",
    "print_msg(messages[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d78660",
   "metadata": {},
   "source": [
    "## **CONVERSATION TRANSCRIPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e94265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[31mSystem:\u001b[0m\n",
      "You are a helpful system administrator. Use the supplied tools to help the user.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "What tools can you use?\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "I can add, remove, and manage tools related to API services and function tools within the\n",
      "`functions` namespace. I also have a capability to execute multiple tool operations in parallel\n",
      "using the `multi_tool_use.parallel` function. If you need a specific API or functionality, let me\n",
      "know, and I can manage the tools accordingly.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "Add a new API service called 'road_digitraffic'. Use the base URL 'https://tie.digitraffic.fi', and\n",
      "the OpenAPI Specification URL 'https://tie.digitraffic.fi/swagger/openapi.json'.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "The new API service 'road_digitraffic' has been successfully added with the base URL\n",
      "'https://tie.digitraffic.fi' and the OpenAPI Specification URL\n",
      "'https://tie.digitraffic.fi/swagger/openapi.json'.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "What tools can you use?\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "I now have access to the following tools within the `functions` namespace:  1. **Road Digitraffic\n",
      "API Tools** (from the recently added 'road_digitraffic' service):    - Access various endpoints\n",
      "related to traffic measurement, weather stations, maintenance tracking, and more.  2. **Multi Tool\n",
      "Execution**:    - `multi_tool_use.parallel`: Execute multiple tools in parallel when they can\n",
      "operate independently.  If you need specific functionalities or data, feel free to ask, and I can\n",
      "use the appropriate tool.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "Can you tell me where exists traffic jam right now?\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "There is a traffic situation report for a traffic jam right now:  - **Location:** Road 6,\n",
      "Lappeenranta, Finland - **Nature of Incident:** Preliminary accident report - **Specific Location:**\n",
      "Between Laihian junction bridge and Muuko interchange - **Coordinates:** Path through multiple\n",
      "points from [28.315513, 61.073364] to [28.348438, 61.084576] - **Start Time:** December 19, 2024,\n",
      "23:08:00 UTC - **Expected End Time:** December 19, 2024, 23:38:14 UTC - **Additional Information:**\n",
      "[Traffic Information and Road Conditions Online](https://liikennetilanne.fintraffic.fi/) -\n",
      "**Contact:** Fintraffic Tieliikennekeskus Tampere, Phone: 02002100, Email:\n",
      "tampere.liikennekeskus@fintraffic.fi  If you need more detailed information about other locations or\n",
      "traffic situations, let me know!\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "Add a new service called `vision` with the functions `llmcam.vision.dtcam.cap` and\n",
      "`llmcam.vision.yolo.detect_objects`.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "The new service 'vision' has been added with the functions `llmcam.vision.dtcam.cap` and\n",
      "`llmcam.vision.yolo.detect_objects`. If you need to utilize these functions, feel free to ask!\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[32mUser:\u001b[0m\n",
      "Show me an image in Lappeenranta with a weather camera and detect objects in it.\n",
      "\u001b[1m\u001b[31m>> \u001b[43m\u001b[34mAssistant:\u001b[0m\n",
      "Here is an image captured from a weather camera in Lappeenranta:  ![Lappeenranta Weather\n",
      "Camera](sandbox:/home/nghivo/tinyMLaaS/llmcam/data/cap_2024.12.19_23:26:51_Imatralle_C0352901.jpg)\n",
      "Unfortunately, no objects were detected in this image. If you have any other requests or need\n",
      "additional information, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print_msgs(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
